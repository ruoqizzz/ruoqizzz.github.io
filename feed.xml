<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ruoqizzz.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ruoqizzz.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-16T17:54:32+00:00</updated><id>https://ruoqizzz.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Lyapunov Function and Theory</title><link href="https://ruoqizzz.github.io/blog/2024/Lyapunov-Function-and-Theory/" rel="alternate" type="text/html" title="Lyapunov Function and Theory"/><published>2024-09-02T11:49:00+00:00</published><updated>2024-09-02T11:49:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Lyapunov-Function-and-Theory</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Lyapunov-Function-and-Theory/"><![CDATA[<p>To understand how to derive the condition \(V'(x)f(x) \leq 0\), let’s break it down step by step within the context of Lyapunov stability theory, which is commonly used to analyze the stability of dynamic systems.</p> <h3 id="1-lyapunov-function-vx">1. <strong>Lyapunov Function \(V(x)\):</strong></h3> <ul> <li>The function\(V(x)\) is chosen or constructed to be a measure of the “energy” or “potential” of the system. For stability analysis, we typically require that: -\(V(x) &gt; 0\) for all\(x \neq 0\) (positive definiteness). -\(V(x) = 0\) at the equilibrium point\(x = 0\).</li> </ul> <h3 id="2-system-dynamicsdotx--fx">2. <strong>System Dynamics\(\dot{x} = f(x)\):</strong></h3> <ul> <li>Consider a dynamic system described by the differential equation\(\dot{x} = f(x)\), where\(\dot{x}\) is the time derivative of the state\(x\), and\(f(x)\) describes the system’s dynamics.</li> </ul> <h3 id="3-time-derivative-of-the-lyapunov-function">3. <strong>Time Derivative of the Lyapunov Function:</strong></h3> <ul> <li>To analyze the stability of the system, we examine how the Lyapunov function\(V(x)\) changes over time as the system evolves.</li> <li> <p>The rate of change of\(V(x)\) with respect to time is given by the total derivative: \(\frac{dV(x)}{dt} = \frac{\partial V(x)}{\partial x} \cdot \frac{dx}{dt} = V'(x) \cdot \dot{x},\) where\(V'(x) = \frac{\partial V(x)}{\partial x}\) is the gradient of\(V(x)\) with respect to\(x\), and\(\dot{x} = f(x)\).</p> </li> <li>Substituting\(\dot{x} = f(x)\) into this equation, we get: \(\frac{dV(x)}{dt} = V'(x) \cdot f(x).\)</li> </ul> <h3 id="4-stability-condition">4. <strong>Stability Condition:</strong></h3> <ul> <li>For the system to be stable, we require that the Lyapunov function\(V(x)\) does not increase over time, meaning that\(\frac{dV(x)}{dt} \leq 0\).</li> <li>This condition implies: \(V'(x) \cdot f(x) \leq 0.\)</li> <li>If\(V'(x)f(x) \leq 0\), then\(V(x)\) is non-increasing along the trajectories of the system. This non-increasing behavior suggests that the system’s “energy” is either decreasing or staying the same, which corresponds to the system being stable or moving toward a stable state.</li> </ul> <h3 id="5-derivation-summary">5. <strong>Derivation Summary:</strong></h3> <ul> <li>The condition\(V'(x)f(x) \leq 0\) is derived by considering the time derivative of the Lyapunov function\(V(x)\).</li> <li>If\(V'(x)f(x) \leq 0\), it guarantees that\(V(x)\) does not increase over time, meaning the system (or algorithm) is stable, as it tends to reduce or maintain its “energy” over time.</li> </ul> <h3 id="example-illustration">Example (Illustration):</h3> <p>Let’s consider a simple system:</p> <p>\(\dot{x} = -x,\) and define the Lyapunov function\(V(x) = \frac{1}{2}x^2\).</p> <ul> <li>The gradient\(V'(x) = x\).</li> <li>The time derivative of\(V(x)\) along the trajectory of the system is: \(\frac{dV(x)}{dt} = V'(x) \cdot \dot{x} = x \cdot (-x) = -x^2 \leq 0.\)</li> </ul> <p>Here,\(V'(x)f(x) \leq 0\) because\(-x^2\) is always non-positive. This means\(V(x)\) decreases over time, which indicates that the system is stable.</p> <h3 id="conclusion">Conclusion:</h3> <p>The condition\(V'(x)f(x) \leq 0\) is derived as a requirement for the Lyapunov function to be non-increasing, which in turn ensures the stability of the system. It indicates that the system is not gaining energy and is either stable or moving towards stability.</p>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[To understand how to derive the condition \(V'(x)f(x) \leq 0\), let’s break it down step by step within the context of Lyapunov stability theory, which is commonly used to analyze the stability of dynamic systems.]]></summary></entry><entry><title type="html">Convergence Analysis of Recursive Sysid with Associated Differential Equation</title><link href="https://ruoqizzz.github.io/blog/2024/Convergence-Analysis-of-Recursive-Sysid-with-Associated-Differential-Equation/" rel="alternate" type="text/html" title="Convergence Analysis of Recursive Sysid with Associated Differential Equation"/><published>2024-08-29T17:49:00+00:00</published><updated>2024-08-29T17:49:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Convergence-Analysis-of-Recursive-Sysid-with-Associated-Differential-Equation</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Convergence-Analysis-of-Recursive-Sysid-with-Associated-Differential-Equation/"><![CDATA[<p>Based on heuristic arguments in previous blogs, we describe a link between the recursive identification algorithms under discussion and a certain associated differential equation. The analysis suggests that the convergence of the algorithm could be studied in terms of stability properties of related differential equations as summarized in heuristic claims.</p> <p>Let’s study the following algorithms</p> \[x(t) = x (t-1) + \alpha Q(t, x(t-1),\phi(t) )\\ \phi(t) = A( x (t-1)) \phi (t-1) + B( x (t-1)) e(t) \label{eq:algo}\] <p>with assumptions</p> <p><strong>C1:</strong> The function \(Q(t, x, \varphi)\) is Lipschitz continuous in \(x\) and \(\varphi\) in any neighborhood of \((\bar{x}, \bar{\varphi})\), where \(\bar{x} \in D_R\) and \(\bar{\varphi}\) is arbitrary: \(\begin{align} |Q(t, x_1, \varphi_1) - Q(t, x_2, \varphi_2)| \leq K(\bar{x}, \bar{\varphi}, \rho, v)\left[|x_1 - x_2| + |\varphi_1 - \varphi_2|\right] \label{eq:recursive_proof} \end{align}\)</p> <p>for \(|x_i - \bar{x}| \leq \rho, |\varphi_i - \bar{\varphi}| \leq v\), where \(\rho = \rho(\bar{x}) &gt; 0\), \(v = v(\bar{\varphi}) &gt; 0\). The Lipschitz constant \(K\) may thus depend on the neighborhood.</p> <p><strong>C2:</strong> The matrix functions \(A(x)\) and \(B(x)\) are Lipschitz continuous in \(x\) for \(x \in D_R\).</p> <p><strong>C3:</strong> The sequence \(\{e(t)\}\) is such that</p> \[\sum_{k=1}^{t} \beta(t, k) Q(k, \bar{x}, \bar{\varphi}(k, \bar{x})) \to f(\bar{x}) \text{ as } t \to \infty \text{ for all } \bar{x} \in D_R.\] <p>Here \(\beta(t, k)\) are the weights corresponding to \(\{ \alpha(t) \}\) such that</p> \[\begin{aligned} \bar{\beta}(t, k) &amp;= \prod_{i=k}^{t}\frac{\alpha(i-1)}{\alpha(i)}[1-\alpha(i)]\\ &amp;=\frac{\alpha(k-1)}{\alpha(t)}\prod_{i=k}^{t}[1-\alpha(i)] &amp;\text{the normalized mecumulative effect of the past}\\ \beta(t, k) &amp;= \alpha(t)\bar{\beta}(t, k) \end{aligned}\] <p>and \(\varphi(t, \bar{x})\) is defined by</p> \[\varphi(t, \bar{x}) = A(\bar{x}) \varphi(t-1, \bar{x}) + B(\bar{x}) e(t), \quad \varphi(0, \bar{x}) = 0.\] <p><strong>C4:</strong> For all \(x \in D_R\) we have, for <strong>some</strong> \(C(\bar{x}, \lambda, c)\),</p> \[\sum_{k=1}^{t} \beta(t, k)[1 + v(k, \lambda, c)] \cdot K(\bar{x}, \varphi(k, \bar{x}), \rho(\bar{x}), v(k, \lambda, c)) \to C(\bar{x}, \lambda, c) &lt; \infty \text{ as } t \to \infty.\] <p>Here \(\lambda\) is the maximum eigenvalue norm of \(A(\bar{x})\), \(v(t, \lambda, c)\) is defined by</p> \[v(t, \lambda, c) \triangleq c \sum_{k=1}^{t} \lambda^{t-k} |e(k)|,\] <p>and \(K\) is the Lipschitz constant defined in C1.</p> <p><strong>C5:</strong> \(\sum_{t=1}^{\infty} \alpha(t) = \infty\).</p> <p><strong>C6:</strong> \(\alpha(t) \to 0 \text{ as } t \to \infty\).</p> <p><strong>Interpretation of C1 and C2:</strong> The function is smooth such that a small changes in \(x\) or \(\phi\) will not give a big changes in \(Q,A,B\).</p> <p><strong>Interpretation of C3:</strong> Recall that \(\sum\beta(t,k)=1\) if \(\gamma(1)=1\) (See PTRI 2.129), which gives</p> \[\sum_{k=1}^T \beta(t,k)Q(k,\bar{x},\phi(k,\bar{x}))\] <p>in C3 is a weighted average of the term \(\{Q(k,\bar{x},\phi(k,\bar{x}))\}\). There in turn are the average asymptotic updating steps that the algorithm uses when \(\{x(k)\}\) stays close enough to a certain value \(x\). Hen the limit \(f(\bar{x})\) assumed to exist in \(C3\) represents an average asymptotic update direction for \(\eqref{eq:recursive_proof}\).</p> <p><strong>Interpretation of C4:</strong> The deviations from the average behavior is bounded by bounding the influence of past errors assuming the worst case with maximum eigenvalue.</p> <p><strong>Theorem 4.1</strong> Consider the algorithm \(\eqref{eq:recursive_proof}\) subject to the conditions C1–C6. Let \(\bar{D}\) be a closed subset of \(D_R\). Assume that there is a constant \(C &lt; \infty\) and a subsequence \(\{t_k\}\) (that may depend on the <strong>particular</strong> sequence \(\{e(r)\}\)) such that \(\begin{align} x(t_k) \in \bar{D} \quad \text{and} \quad |\varphi(t_k)| &lt; C. \label{eq:x_close_to_DR} \end{align}\)</p> <p>Assume also that there exists a twice-differentiable function \(V(x)\) in \(D_R\), such that, with \(f(x)\) given by C3,</p> \[V'(x)f(x) \leq 0, \quad x \in D_R.\] <p>Then either</p> \[x(t) \to D_c = \{x | x \in D_R \text{ and } V'(x)f(x) = 0 \} \text{ as } t \to \infty\] <p>or</p> \[\{x(t)\} \text{ has a cluster point on the boundary of } D_R.\] <p>which means that there exists a subsequence \(\{t_j\}\) such that \(x_j\) tends to the boundary of \(D_R\) as \(j\) approcahces infinity.</p> <p>The asymptotic average updating direction for the algorihtm is according to C3 given by \(f(x)\), so the corresponding differential equation is</p> \[\begin{align} \frac{d}{d\tau}x(\tau) = f(x(\tau)) \label{eq:de} \end{align}\] <p>The lyapunov function ensures that all trejectories of this differential equation that start in \(D_R\) will either leave \(D_R\) or converge to D_c as time tends to infinity.</p> <p>The theorem 4.1. holds for any sequence \(\{e(t)\}\) subject to C4 and C4. If \(\{e(t)\}\) is regarded as a stochastic process, such that C3 and C4 holds w.p.1, then the conclusion of the theorem also hold w.p.1.</p> <p>Let’s first check some examples.</p> <p><strong>Example: Estimation of Mean</strong></p> <p>Consider the algorithm for estimating the mean of a random variable,</p> \[x(t) = x(t - 1) + \frac{1}{t} [e(t) - x(t - 1)],\] <p>where \(e(t)\) represents a sequence of observations of the random variable. It can be seen as a special case of general form</p> \[Q(t, x, \varphi) = \varphi - x, \quad \varphi(t) = e(t) \quad \text{(i.e., } A(x) = 0, B(x) = 1\text{)}, \quad \text{and } \gamma(t) = \frac{1}{t}.\] <p><strong>Verification of Conditions</strong></p> <p><strong>C1 and C2</strong>:</p> <ul> <li> <p>Conditions C1 and C2 are trivially satisfied with \(D_R = \mathbb{R}\)</p> </li> <li> <p>For C1,\(K(x, \varphi, \rho, v)\)can be taken as 1.</p> </li> </ul> <p><strong>C3</strong>:</p> <ul> <li> <p>In C3, it is found that \(\varphi(t, x) = e(t)\) and that \(\beta(t, k) = \frac{1}{t}\) for \(\alpha(t) = \frac{1}{t}\).</p> </li> <li> <p>The condition for convergence then reads: \(\frac{1}{t} \sum_{k=1}^{t} [e(k) - x] \text{ should converge.}\)</p> <p>This is satisfied if the sequence \(\{e(t)\}\) is such that: \(\frac{1}{t} \sum_{k=1}^{t} e(k) \to m \text{ as } t \to \infty.\)</p> <p>Then \(f(x)=m-x\).</p> </li> </ul> <p><strong>C4</strong>:</p> <ul> <li> <p>For C4, since \(A(x) = 0\), the maximum eigenvalue \(\lambda\) is also 0, which implies \(v(t, \lambda, c) = 0\). The condition simplifies to: \(\sum_{k=1}^{t} \beta(t, k) \to C \text{ as } t \to \infty,\)</p> <p>which is satisfied with \(C = 1\).</p> </li> </ul> <p><strong>C5 and C6</strong>:</p> <ul> <li>These conditions are satisfied for \(\gamma(t) = \frac{1}{t}\).</li> </ul> <p><strong>Differential Equation</strong></p> <p>The associated differential equation (d.e.) for this algorithm is:</p> \[\dot{x} = m - x,\] <p>which is globally asymptotically stable with \(x = m\) as the stationary point.</p> <p>We can take a Lyapunov function \(V(x) = \frac{1}{2}(m - x)^2\), which leads to:</p> \[V'(x)f(x) = -(m - x)^2,\] <p>which is negative for all \(x\). This satisfies the conditions of Theorem 4.1, indicating that \(x(t)\) will tend to \(m\) as \(t\) approaches infinity.</p> <h3 id="exist-issues">Exist issues</h3> <ul> <li> <p>Regulation C1-C4 only holds for \(x\in D_R\), Outside \(D_R\) the d.e. is not defined and thus we do not know the behavior of the algorithm. Thus we must assume by \(\refeq{ eq:x_close_to_DR }\) that the estimates are inside \(\bar{D} \in D_R\) infinitely often, so that they will eventually be captured by a trajectory.</p> </li> <li>Lyapunov Function assures the stability of differential equation \(V\) but it does not necessarily mean that every possible condition will lead to convergence to the equilibrium point. So \(D_R\) is not necessarily the domain of attraction.</li> <li>Once out of \(D_R\), there is no control over the estimate sequence except from \(\refeq{eq:x_close_to_DR}\) we know that it might go back to \(D_R\), but we do not know when and how often this could happen.</li> </ul> <h3 id="example-nonlinear-system-with-multiple-equilibria">Example: Nonlinear System with Multiple Equilibria</h3> <p>Consider a simple nonlinear system with the following dynamics: \(\dot{x} = -x(x - a)(x - b)\) where \(a\) and \(b\) are constants, with \(0 &lt; a &lt; b\). This system has three equilibrium points:</p> <ul> <li>\(x = 0\) (unstable equilibrium),</li> <li>\(x = a\) (stable equilibrium),</li> <li>\(x = b\) (unstable equilibrium).</li> </ul> <p>Suppose the set \(D_R\) corresponds to the region where the system exhibits regular, predictable behavior, and it includes the stable equilibrium point \(x = a\). The boundary of \(D_R\) could correspond to the unstable equilibrium point \(x = b\). If the estimates \(x(t)\) are influenced by noise, errors, or model inaccuracies, they might be pushed out of the region of attraction for the stable point \(x = a\). For example:</p> <ul> <li>If \(x(t)\) is near \(b\) and experiences a perturbation that pushes it beyond \(b\), it might leave \(D_R\) (just as it might leave the region between \(a\) and \(b\) in the example).</li> <li>Once outside \(D_R\), the system could move towards an area where the stability conditions no longer apply (similar to how \(x(t)\) might move towards \(x = 0\) in the example, where different dynamics govern the behavior).</li> </ul> <h2 id="projection-algorithms">Projection Algorithms</h2> <p>To force the estimates to remain inside a compact subset \(\bar{D}\), \(\bar{x}(t) = x(t - 1) + \gamma(t) Q(t, x(t - 1), \phi(t)), \\ x(t) = \begin{cases} \bar{x}(t) &amp; \text{if } \bar{x}(t) \in \bar{D}, \\ x(t-1) &amp; \text{if } \bar{x}(t) \notin \bar{D}. \end{cases}\) <strong>Corollary to Theorem 4.1:</strong></p> <p>It states that under the same assumptions as in Theorem 4.1, one of the following must hold:</p> <ol> <li>\(x(t) \rightarrow D_c\) as \(t \rightarrow \infty\), where \(D_c\) is a stable set within \(\bar{D}\).</li> <li>\(x(t) \rightarrow \delta \bar{D}\) as \(t \rightarrow \infty\), where \(\delta \bar{D}\) is the boundary of \(\bar{D}\).</li> </ol> <p>Second situation may only hold if there is a trajectory of the differential equation that leaves \(\bar{D}\).</p> <h3 id="results">Results</h3> <p><strong>Result 4.1 (Theorem 2 in Ljung, 1977b)</strong></p> <p>Suppose that the sequence \(x(t)\), given by the recursive algorithm \(\eqref{eq:algo}\) converges to some value \(x^*\) with a probability greater than zero. Then, two conditions must hold:</p> <ol> <li><strong>\(f(x^*) = 0\)</strong>: This condition ensures that \(x^*\) is a fixed point of the function \(f(x)\) defined in condition C3.</li> <li><strong>Eigenvalues of \(H(x^*)\)</strong>: \(H(x^*)\) is defined as the derivative (Jacobian matrix) of \(f(x)\) with respect to \(x\) evaluated at \(x^*\). The condition requires that all the eigenvalues of \(H(x^*)\) must lie in the left half of the complex plane ensuring the stability of the equilibrium point \(x^*\).</li> </ol> <p><strong>Result 4.2 (Theorem 3 in Ljung, 1977b)</strong></p> <p>The upper bound on the probability that \(x(t)\) does not remain in an \(\epsilon\)-neighborhood of the corresponding trajectory of \(\eqref{eq:de}\) over the interval from \(t = t_0\) to \(t = N\) is \(\frac{K}{\epsilon^{4p}} \sum_{j=t_0}^{N} \alpha(j)^p,\) where \(K\) is a constant, \(\alpha(j)\) is the learning rate (or step size), and \(p\) is a positive exponent.</p>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[Based on heuristic arguments in previous blogs, we describe a link between the recursive identification algorithms under discussion and a certain associated differential equation. The analysis suggests that the convergence of the algorithm could be studied in terms of stability properties of related differential equations as summarized in heuristic claims.]]></summary></entry><entry><title type="html">Convergence Analysis of Recursive Sysid - A Heuristic Discussion</title><link href="https://ruoqizzz.github.io/blog/2024/Theory-Heuristic-Discussion/" rel="alternate" type="text/html" title="Convergence Analysis of Recursive Sysid - A Heuristic Discussion"/><published>2024-08-26T16:36:00+00:00</published><updated>2024-08-26T16:36:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Theory-Heuristic-Discussion</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Theory-Heuristic-Discussion/"><![CDATA[<p>Here we consider the basic structure for algorithms related to quadratic criteria</p> \[\begin{align} \begin{aligned} &amp;\varepsilon(t) = y(t)-\hat{y}(t) \\ &amp;R(t) = R(t-1) + \alpha(t)[\eta(t)\Lambda^{-1}(t)\eta^T(t) - R(t-1)]\\ &amp;\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \eta(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}}\\ &amp;\xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t)\\ &amp;\begin{pmatrix} \hat{y}(t+1) \\ \text{col } \eta(t+1) \end{pmatrix} = C(\hat{\theta}(t)) \xi(t+1). \end{aligned} \label{eq:general_form} \end{align}\] <p>where \(\eta(t)\) is a vector related to the gradient of the predition \(\hat{y}(t)\) w.r.t \(\hat{\theta}\), for exawmple \(\psi, \phi, \zeta\) discussed before and \(z(t) = \begin{pmatrix} y(t) \\ u(t) \end{pmatrix}\).</p> <p>When the criteria is general \(\bar{\mathbb{E}}l(t,\theta,\varepsilon(t,\theta))\), then the algorithm can changed to</p> \[\begin{align} &amp;R(t) = R(t-1) + \alpha(t) H\left(t, R(t-1),\hat{\theta}(t-1),\varepsilon(t), \eta(t)\right)\\ &amp;\hat{\theta}(t) = \hat{\theta}(t-1) + \alpha(t) R^{-1}(t) h\left(t,\hat{\theta}(t-1),\varepsilon(t), \eta(t)\right)\\ \end{align}\] <p>where functions \(H\) and \(h\) are related to the criterion function \(l\).</p> <p>Convergence analysis is in general diffusion. A major reason is the coupling between \(\hat{\theta}(t)\), \(\eta(t)\) and \(\xi(t)\) (like a feedback loop) which makes the mapping from \(z^t\) to \(\hat{\theta}(t)\) complex.</p> <p>There are several tools for convergence analysis can be used:</p> <ol> <li>Lyapunov Functions</li> <li>Stochastic Approximation</li> <li>Martingale Convergence Theorems</li> <li>Stabiliy of Differentail Equqations</li> </ol> <p>Here we mainly focus on associating a deterministic differential equation with the recursive algorithm due to its general applicability. The stability of this differential equation can then be analyzed to infer the stability of the recursive algorithm.</p> <h2 id="an-associated-differential-equation-a-heuristic-discussion">An Associated Differential Equation: A Heuristic Discussion</h2> <p>For ufficiently large \(t\), the step size \(\alpha(t)\) will be arbitartily small due to our assumption that \(\alpha(t)\rightarrow 0\) as \(t\rightarrow 0\). Then the estimiates \(\{\hat{\theta}(t)\}\) will change more and more sloowly. Let take a look a this consequences, (Check book (3.51) to (3.54) for details here.)</p> \[\xi (t)=\sum_{j=0}^{t-1} \prod_{k=j+1}^{t-1}\left [A(\hat{\theta}(k))\right] \xi(t) B(\hat{\theta}(j))z(j) \label{eq:xi_t+1}\] <p>Suppose now that \(\hat{\theta}(k)\) belongs to a small neighborhood of a value \(\bar{\theta}\) for \(t-K \leq k \leq t-1\), such that \(\bar{\theta}\in \mathcal{D}_s\) where \(\forall \theta \in \mathcal{D}_s\), \(A(\theta)\) has all eighven values strictly inside the unit circle. Then, if the neighborhood is small enough, we can write</p> \[\prod_{k=t-K}^{t-1}A(\hat{\theta}(k)) \approx A(\bar{\theta})^K,\] <p>which has a norm smaller than \(C\cdot \lambda^K\) for some \(\lambda &lt;1\). For large enough \(K\), we may thus approximate \(\eqref{eq:xi_t+1}\) as</p> \[\xi (t) \approx \sum_{j=0}^{t-1} A(\bar{\theta})^{t-j-1} \xi(t) B(\bar{\theta})z(j)\] <p>Now we can add terms cooresponding to \(A(\bar{\theta})^{t-j-1} \xi(t) B(\bar{\theta})z(j)\) for \(j&lt;t-K\) to this sum. Since \(A(\bar{\theta})\) is stable, this wil only make an arbitarily small change. Then we have</p> \[\xi (t) \approx \xi (t,\bar{\theta}) \triangleq \sum_{j=0}^{t-1} A(\bar{\theta})^{t-j-1} \xi(t) B(\bar{\theta})z(j)\] <p>Which can be written recursively as</p> \[\begin{align} \begin{aligned} &amp;\xi (t+1,\bar{\theta}) = A(\bar{\theta}) \xi (t,\bar{\theta})+B(\bar{\theta})z(t),\\ &amp;\xi (0,\bar{\theta})=0. \end{aligned} \label{xi_theta_bar} \end{align}\] <p>As a consequence we also have</p> \[\begin{align} \begin{aligned} \hat{y}(t) \approx y(t\vert\bar{\theta}), \eta (t)\approx \eta(t,\bar{\theta}),\\ \varepsilon (t)\approx \varepsilon (t,\bar{\theta}) \end{aligned} \label{eq:approximation} \end{align}\] <p>where</p> \[\begin{align} \begin{pmatrix} y(t\vert\bar{\theta}) \\ \text{col } \eta(t,\bar{\theta}) \end{pmatrix}&amp;=C(\bar{\theta}) \xi(t,\bar{\theta}) ,\\ \varepsilon(t,\bar{\theta})&amp;=y(t)-\hat{y}(t\vert\bar{\theta}) \end{align}\] <p>When \(\hat{\theta}(t)\) is close to \(\bar{\theta}\) and \(R(t)\) is close to \(\bar{R}\) and \(t\) is large we can consequentily use the approximation \(\eqref{eq:approximation}\) to conclude that</p> \[\begin{align} \begin{aligned} &amp;\hat{\theta}(t) \approx \hat{\theta}(t-1) + \alpha(t) \bar{R}^{-1}(t) \eta(t, \bar{\theta}) \Lambda^{-1} \varepsilon(t,\bar{\theta}), \\ &amp;R(t) = R(t-1) + \alpha(t)\left [\eta(t,\bar{\theta})\Lambda^{-1}(t)\eta^T(t,\bar{\theta}) - \bar{R}\right]\\ \end{aligned} \end{align}\] <p>Introduce the expected values</p> \[\begin{align} \begin{aligned} f(\bar{\theta}) \triangleq \mathbb{E}\eta(t, \bar{\theta}) \Lambda^{-1} \varepsilon(t,\bar{\theta}),\\ G(\bar{\theta}) \triangleq \mathbb{E}\eta(t, \bar{\theta}) \Lambda^{-1} \eta^T(t,\bar{\theta}) \end{aligned} \label{eq:f_G} \end{align}\] <p>where expectation is over \(z^t\). Since \(t\) is large, we have neglected the transients in \(\eqref{xi_theta_bar}\) and the RHS of \(\eqref{eq:f_G}\) to be time-invariant. We thus have</p> \[\begin{align} \begin{aligned} &amp;\hat{\theta}(t) \approx \hat{\theta}(t-1) + \alpha(t) \bar{R}^{-1}(t) f(\bar{\theta}) + \alpha(t) v(t), \\ &amp;R(t) \approx R(t-1) + \alpha(t)\left [G(\bar{\theta}) - \bar{R}\right] + \alpha(t)w(t) \end{aligned} \label{eq_theta_R_approx} \end{align}\] <p>where \(\{v(t)\}\) and \(\{w(t)\}\) are zero-mean random variables.</p> <p>Let \(\Delta\tau\) be a small number and let \(t, t'\) be defined by</p> \[\begin{align} \sum_{k=t}^{t'}\alpha(k)=\Delta \tau \label{eq:delta_tau} \end{align}\] <p>If \(\hat{\theta}(t)=\bar{\theta}\) and \(R(t)=\bar{R}\), we then have from \(\eqref{eq_theta_R_approx}\)</p> \[\begin{align} \begin{aligned} &amp;\theta(t')\approx \bar{\theta} + \Delta\tau \bar{R}^{-1} f(\bar{\theta}) + \sum_{k=t}^{t'}\alpha(k) v(k), \\ &amp;R(t') \approx \bar{R} +\Delta\tau\left [G(\bar{\theta}) - \bar{R}\right] + \sum_{k=t}^{t'}\alpha(k)w(k). \end{aligned} \end{align}\] <p>Since \(v(k)\) and \(w(k)\) have zero means, the contribution forom the third terms of RHS will be an order of magnitude less than those from second terms. Therefore</p> \[\begin{align} \begin{aligned} &amp;\theta(t')\approx \bar{\theta} + \Delta\tau \bar{R}^{-1} f(\bar{\theta}) \\ &amp;R(t') \approx \bar{R} +\Delta\tau\left [G(\bar{\theta}) - \bar{R}\right] \end{aligned} \label{eq:t'_approx} \end{align}\] <p>With a change of time scale, according to \(\eqref{eq:delta_tau}\) such that \(t \leftrightarrow \tau\) and \(t' \leftrightarrow \tau +\Delta \tau\), we could regard \(\eqref{eq:t'_approx}\) as a scheme to solve the differential equation with small \(\Delta \tau\),</p> \[\begin{align} \begin{aligned} &amp;\frac{d}{d\tau}\theta_D(\tau) = \bar{R}^{-1}f(\theta_D(\tau))\\ &amp;\frac{d}{d\tau}R_D(\tau) =G(\bar{\theta}) - R_D(\tau) \end{aligned} \label{eq:ODE} \end{align}\] <p>Here the subscript \(D\) is used to distinguish the solution of \(\eqref{eq:ODE}\) from the variables in \(\eqref{eq:general_form}\). The chain of arguments suggests that if for some large \(t_0\)</p> \[\hat{\theta}(t_0) = \theta_D(t_0), R(t_0)=R_D(t_0), \sum_{k=1}^{t_0}\alpha(k)=\tau_0,\] <p>then for \(t&gt;t_0\),</p> \[\begin{align} \hat{\theta}(t) \approx \theta_D(\tau), R(t_0)\approx R_D(\tau), \sum_{k=1}^{t_0}\alpha(k)= \tau, \label{eq:connect_t_tau} \end{align}\] <p>which can be interpreted as the solution of \(\hat{\theta}(t)\) and \(R(t)\) can be approximiated by the solution of differential equation \(\eqref{eq:ODE}\).</p> <p>These arguments have of coiurse been entire heuristic. They point, however, to the results \(\eqref{eq:connect_t_tau}\) that asymptotically the algorithm \(\eqref{eq:general_form}\) can be linked to the differential equation \(\eqref{eq:ODE}\). The estmiate should in some sense follow the trajectories of \(\eqref{eq:ODE}\) asymptotically.</p> <h3 id="the-connection-between--eqrefeqgeneral_form--and--eqrefeqode">The connection between \(\eqref{eq:general_form}\) and \(\eqref{eq:ODE}\).</h3> <p><strong>(A)</strong> Suppose \(D_c\) is an invariant set of \(\eqref{eq:ODE}\) and \(D_A\) is its domain of attraction. Then if \(\hat{\theta}(t)\in D_A\) sufficiently often, the estimate will tend to \(D_c\) w.p.1 as \(t\) approaches infinity.</p> <p><strong>(B)</strong> Only stable stationay points of \(\eqref{eq:ODE}\) are possible convergence points for algorithm \(\eqref{eq:general_form}\).</p> <p><strong>(C)</strong> The trajectories \(\theta_D(\tau)\) of \(\eqref{eq:ODE}\) are the “asymptotic paths” of the estimates \(\hat{\theta}(t)\), generated by \(\eqref{eq:general_form}\) .</p> <p>All above conditions can be proven to be formally correct. See the later post.</p> <h2 id="the-recipe-for-convergence-analysis-of--eqrefeqgeneral_form">The recipe for convergence analysis of \(\eqref{eq:general_form}\)</h2> <ol> <li>Compute the prediction errors \(\varepsilon(t, \theta)\) and gradient approximations \(\eta(t,\theta)\) that would be obtained for a fixed and constant model \(\theta\)</li> <li>Evaluate the average updating direction for the algorithm, based on these variables, see \(\eqref{eq:f_G}\)</li> <li> <p>Define a differential equation that has this direction as the right hand side</p> \[\dot{\theta_D} = \bar{R}^{-1}f(\theta_D)\\ \dot{R_D} =G(\bar{\theta}) - R_D\] </li> <li>Study the stability properties of this differential equation.</li> </ol>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[Here we consider the basic structure for algorithms related to quadratic criteria]]></summary></entry><entry><title type="html">Preview of Asymptotic Properties of Recursive Identification Methods</title><link href="https://ruoqizzz.github.io/blog/2024/Theory-Preview/" rel="alternate" type="text/html" title="Preview of Asymptotic Properties of Recursive Identification Methods"/><published>2024-08-26T11:52:00+00:00</published><updated>2024-08-26T11:52:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Theory-Preview</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Theory-Preview/"><![CDATA[<h2 id="preview-of-asymptotic-properties-of-recursive-identification-methods">Preview of Asymptotic Properties of Recursive Identification Methods</h2> <p>The general family of recursive algorithms can be written as</p> \[\begin{align} \label{eq:quad_criterion_with_general_form:start} &amp;\varepsilon(t) = y(t)-\hat{y}(t) \\ &amp;\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)]\\ &amp;\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}}\\ &amp;\xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t)\\ &amp;\begin{pmatrix} \hat{y}(t+1) \\ \text{col } \psi(t+1) \end{pmatrix} = C(\hat{\theta}(t)) \xi(t+1). \label{eq:quad_criterion_with_general_form:end} \end{align}\] <p>where \(\psi(t)\) which is the gradient of the prediction w.r.t \(\theta\) plays a crucial role.</p> <p><strong>Assumption</strong> The generation of the input sequence \(\{u(t)\}\) is not based on the current estimates \(\theta\).</p> <h3 id="recursive-prediction-error-methods">Recursive Prediction Error Methods</h3> <p>Consider the general criterion function</p> \[\bar{V}(\theta)=\bar{\mathbb{E}}l(t,\theta,\varepsilon(t,\theta))\] <p>where \(\bar{\mathbb{E}}\) is defined as</p> \[\bar{\mathbb{E}} f(t) = \lim_{N\rightarrow \infty}\frac{1}{N}\mathbb{E}f(t)\] <p>This algorithm does exactly what it is required to:</p> <blockquote> <p>The estimate \(\hat{\theta}(t)\) will converge w.p.1to a local minimum of $$\bar{V}$ as t approaches infinity. (This will be shown later in theorems x).</p> </blockquote> <p>There are two issues to be discussed</p> <ol> <li>“<strong><em>Local</em></strong>”: If \(\bar{V}(\theta)\) has several local minima, we can not expect global convergence to a gloabal minimum.</li> <li>The quoted convergence results holds <em>whether or not the <strong>true system</strong> belongs to the model set</em>: Even if the true system is more complex then the models, the identification procedure will picl the best approximation of the system w.r.t the criterion.</li> </ol> <h4 id="asymptotic-distribution">Asymptotic Distribution</h4> <p>Suppose we use a Gauss-Newton algorithm with a gain sequence such that \(t \cdot \alpha(t)\rightarrow 1\) as \(t\rightarrow \infty\), then we have</p> \[\sqrt{t}(\theta(t) - \theta^*) \xrightarrow{d} \mathcal{N}(0, P)\] <p>where $$\theta^*$ denotes the convergence value. This result implies that as more data becomes available, the estimation error becomes smaller, but the distribution of the scaled error approaches a normal distribution. The matrix $P$ , which describes the precision of the parameter estimates, is the same as the offline case.</p> <p>If the true system is in the model set and \(\theta^*=\theta_\circ\) then the prediction errors \(\{\varepsilon(t,\theta_\circ)\}\) is a sequence of indenpendent random vectors each of zero mean and covariance matrix $$\Lambda_\circ$ and with recursive algorithms used, we have</p> \[\begin{align} R^{-1}(t)\rightarrow P = \left[ \bar{\mathbb{E}}\psi(t,\theta_\circ)\Lambda_\circ\psi(t,\theta_\circ)^T \right]^{-1}~~~~w.p.1.\text{ as }t\rightarrow\infty, \label{eq:RPEM_convergence_R} \end{align}\] <p>where \(R(t)\) is the matrix in the recursive Gauss-Newton algorithm and \(P\) is the asymptotic covariance matrix.</p> <h3 id="pseudolinear-regressions">Pseudolinear Regressions</h3> <p>According to the definition,</p> \[\psi(t) = -\frac{\partial \hat{y}(t\vert \theta)}{\partial \theta}\] <p>If the implicit \(\theta\)-dependencen in \(\phi(t,\theta)\) is neglected, we could obtain an appeoximate expression</p> \[\frac{\partial \hat{y}(t\vert \theta)}{\partial \theta} \approx \phi(t,\theta).\] <p>With this approximation, the recursive algorithm can be rewritten as</p> \[\begin{align} &amp;\varepsilon(t) = y(t)-\hat{\theta}^T(t-1)\phi(t) \\ &amp;R(t)=R(t-1) +\alpha (t)\left[\phi(t)\phi^T(t) - R(t-1)\right]\\ &amp;\hat{\theta} = \hat{\theta}(t-1) + \alpha(t) R^{-1}\phi (t)\varepsilon (t) \end{align}\] <p>Due to the system is modeled as linear in the parameters, even if the relationship between the input and output is nonlinear, we call this algorithm “psuedolinear regression”.</p> <p>Usually, we use filter \(\phi(t)\) as the approximated gradient. The filters is associated with the estimate \(\hat{\theta}(t)\) and depends on the particular model set. There are two examples</p> <ul> <li> <p>ARMAX model \(A(q^{-1})y(t)=B(q^{-1})u(t)+C(q^{-1})e(t)\)</p> <p>then</p> \[\psi(t)=\frac{1}{\hat{C}_t(q^{-1})}\phi(t)\] <p>where \(\hat{C}_t(q^{-1})\) is the current estimate of the $C$-polynomial.</p> </li> <li> <p>Output error model</p> \[y(t)=\frac{B(q^{-1})}{F(q^{-1})}u(t)+e(t)\] <p>then</p> \[\psi(t)=\frac{1}{\hat{F}_t(q^{-1})}\phi(t)\] </li> </ul> <p>PLR can be seen as neglecting the filtering. Let’s give a closer look the influence of its approximation in ARMAX case.</p> <p>The true system is given by</p> \[A_\circ(q^{-1})y(t)=B_\circ(q^{-1})u(t)+C_\circ(q^{-1})e(t),\] <p>then a sufficient condition for convergence of \(\hat{\theta}(t)\) to the true parameters \(\theta_\circ\) is that</p> \[\vert C_\circ(e^{i\omega})-1\vert &lt; 1~\forall \omega\] <p>provided the input is general enough. <span style="color:red"> WHY?</span></p> <p>This condition can be interpreted as a measure of how good an approximation it is to replace \(\psi(t)\) by \(\phi(t)\) close to $$\hat{\theta}(t) = \theta_\circ$. It can also be rewritten as</p> \[\text{Re}\left[\frac{1}{C_\circ(e^{i\omega})}-\frac{1}{2}\right]&gt;0~~\forall \omega,\] <p>which is often expressed as “the filter $$\frac{1}{C_\circ(q^{-1})}-\frac{1}{2}$ is strictly positive real.”</p> <p><strong>Proof:</strong></p> \[\begin{align}\text{Re}\left[\frac{1}{z}-\frac{1}{2}\right]&gt;0 \rightleftharpoons \frac{2\text{Re }(z) -\vert z\vert^2}{\vert z\vert^2}&gt;0 \rightleftharpoons 2\text{Re }(z) &gt;\vert z\vert^2,\\ \vert z - 1\vert &lt; 1 \rightleftharpoons (z-1)(\bar{z}-1)&lt;1 \rightleftharpoons \vert z\vert^2-2\text{Re}(z) + 1&lt; 1 \rightleftharpoons \vert Z(e^{i\omega})-1 \vert &lt; 1. \end{align}\] <p>While the aforementioned conditions are <em>sufficient</em> for convergence, it is also known that PLR algorithms may not converge. In fact, if</p> \[\begin{align} \text{Re} C_\circ(e^{i\omega})&gt;0~~\forall \omega \label{eq:reC} \end{align}\] <p>does not hold, we can always an A-polynomial, B-polynomial and a input signal such that the probability that \(\hat{\theta}(t)\) converges to the desired value \(\theta_\circ\) is zero. This means that as a condition on C-polynomial alone equation \(\eqref{eq:reC}\) is necessary to assure convergence.</p> <p>Note that these convergence results apply only if the true system indeedn belongs to the model set!</p> <p>No explicit expression for the asympototic convariance matrix for the estimates obtained by PLR is knwon in general. It is not ture for a PLR algorithm that \(R(t)\) converges to the asymptotic covariance matrix in contrast to the case in \(\eqref{eq:RPEM_convergence_R}\).</p> <h3 id="instrumental-variable">Instrumental Variable</h3> <p>In linear regression, we assume that</p> \[\mathbb{E}\phi(t)v(t)=0,\] <p>such that \(\theta_\circ\) is a solution to</p> \[\mathbb{E}\phi(t)[y(t) - \phi^T(t)\theta]=0.\] <p>This means that \(v(t)\) must be zero mean and uncorrelated with \(\phi(t)\).</p> <p>For linear different equations</p> \[\begin{align} y(t)+a_1y(t-1) + \dots + a_n y(t-n) = b_1u(t-1)+\dots+b_mu(t-m)+v(t) \label{eq:linear_diff} \end{align}\] <p>where \(\{v(t)\}\) is s sequence of zero-mean disturbances of unspecified character, not necessarily white noise. The aforementioned assumption leads to $n=0$ and \(\{v(t)\}\) and \(\{u(t)\}\) are independent or \(\{v(t)\}\) is white noise.</p> <p>Let</p> \[\phi^T(t)=\begin{bmatrix} -y(t-1) &amp;\dots -y(t-n)&amp;u(t-1)&amp;\dots u(t-m) \end{bmatrix}\] <p>Then we can rewrite \(~\eqref{eq:linear_diff}\) as</p> \[\begin{align} \begin{aligned} y(t)=\theta^T\phi(t)+v(t) \end{aligned} \label{eq:linear_phi} \end{align}\] <p>Therefore, in order to obtain a sequence of estimates that converges to \(\theta_\circ\) as \(t\) approahces infinity, we should instead solve</p> \[\mathbb{E} \zeta (t)[y(t)-\phi^T(t)\theta]=0\] <p>where \(\zeta (t)\) should be uncorrelated with \(v(t)\) but correlated with the gradient</p> \[\mathbb{E}\zeta (t)v(t)=0\\ \mathbb{E}\zeta (t)\phi^T(t) \text{ positive definite or at least nonsigular.}\] <p>The vector \(\zeta (t)\) is called the instrumental variable (IV) and the algorithm</p> \[\hat{\theta}(t) = \hat{\theta}(t-1) +\alpha(t) R^{-1}(t)\zeta (t)[y(t)-\phi^T(t)\hat{\theta}(t-1)]\] <p>is a recursive instrumental varibale (RIV) algorithm.</p> <p>There are many ways of choosing \(R(t)\) and \(\zeta(t)\). Here we first focus on the refined IV</p> \[\begin{align} &amp;\hat{\theta}(t) = \hat{\theta}(t-1) +\alpha(t) R^{-1}(t)\zeta (t)[y_F(t)-\phi_F^T(t)\hat{\theta}(t-1)],\\ &amp;R(t)=R+\alpha(t)[\zeta(t)phi^T_F(t) - R(t-1)]\\ &amp;y_F(t)=T(q^{-1})y(t)\\ &amp;\phi_F=T(q^{-1})\phi(t)\\ &amp;t\cdot\alpha(t)\rightarrow 1 \text{ as }t\rightarrow \infty \end{align}\] <p>Convergence and asymptotic properties of the nonsymmetric method can be established by examination of the offline expression</p> \[\hat{\theta}(t)=\left[ \sum_{1}^t\zeta(k)\phi_F^T(k) \right]^{-1} \sum_{1}^t\zeta(k)y_F(k)\] <p>when the filters are invovled in the generation of \(\{\zeta(t)\}\) are time-invariant.</p> <p>If \(\eqref{eq:linear_phi}\) describes the true system, then \(\hat{t}\) will tend to \(\theta_\circ\) as \(t \rightarrow \infty\) if</p> \[\bar{\mathbb{E}}\zeta(t)\phi^T(t)\] <p>is nonsingular and</p> \[\bar{\mathbb{E}}\zeta(t)v(t)=0.\] <p>In general, these two conditions depend on the properties of true system and the choice of \(\{\zeta(t)\}\) and \(T(q^{-1})\). Also, it can be shown that</p> \[\sqrt{t}(\theta(t) - \theta_\circ) \xrightarrow{d} \mathcal{N}(0, \bar{P})\] <p>where an explicit expression of \(\bar{P}\) can be given in terms of the true system, the properties of $${v(t)}$ and the chosen instrumental variables and filters.</p>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[Preview of Asymptotic Properties of Recursive Identification Methods]]></summary></entry><entry><title type="html">The users’ summary of a general recursive identification method</title><link href="https://ruoqizzz.github.io/blog/2024/User-Summary/" rel="alternate" type="text/html" title="The users’ summary of a general recursive identification method"/><published>2024-08-26T10:37:00+00:00</published><updated>2024-08-26T10:37:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/User-Summary</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/User-Summary/"><![CDATA[<h2 id="a-general-framework">A general framework</h2> <p>The model set is defined in general terms as a one-step-ahead predictor \(\hat{y}(t \vert \theta)\) that depends on the model parameter vector \(\theta\). This prediction can be formed using a linear finite-dimensional filter acting on the observed input-output data \(\{z(t)\}\)</p> \[\phi(t+1, \theta) = \mathscr{F}(\theta)\phi(t,\theta) + \mathscr{G}(\theta)z(t)\\ \hat{y}(t\vert \theta) = \mathscr{H}(\theta)\phi(t,\theta).\] <p>There are some particular explaples of model sets</p> <ul> <li> <p>Linear Regression Models \(\hat{y}(t\vert \theta) = \phi^T(t)\theta\)</p> </li> <li> <p>A General SISO Model: \(A(q^{-1})y(t)=\frac{B(q^{-1})}{F(q^{-1})}u(t)+\frac{C(q^{-1})}{D(q^{-1})}e(t)\)</p> </li> <li> <p>State-space Models \(x(t+1) = F(\theta)x(t)+G(\theta)u(t)+w(t)\\ y=H(\theta)x(t)+e(t)\)</p> </li> </ul> <p>For the general form, the gradient of \(\hat{y}(t \vert \theta)\) w.r.t \(\theta\), denoted by \(\psi(t,\theta)\) can be computed by means of</p> \[\begin{align} \label{eq:quad_criterion_with_general_form:start} &amp;\varepsilon(t) = y(t)-\hat{y}(t) \\ &amp;\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)]\\ &amp;\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}}\\ &amp;\xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t)\\ &amp;\begin{pmatrix} \hat{y}(t) \\ \text{col } \psi(t) \end{pmatrix} = C(\hat{\theta}(t-1)) \xi(t). \label{eq:quad_criterion_with_general_form:end} \end{align}\] <p>Here \(\{\alpha(t)\}\) is a sequence of positive scalars, \(D_\mathscr{M}\) is the projection into the stable model region. \(R(t)\) is a positive definite matrix that modefies the seasrch direction. For example, there are two common choices,</p> <ul> <li> <p>Gauss-Newton direction \(R(t)=R+\gamma\left[ \psi(t)\hat(t){\Lambda(t)}\psi^T(t)-R(t-1). \right]\)</p> </li> <li> <p>Gradient direction \(\begin{align} R(t) &amp;= r(t)\cdot I\\ r(t) &amp;= r(t-1)+\gamma(t) \left[ \text{tr}\psi(t)\hat{\Lambda(t)}\psi^T(t)-r(t-1) \right] \end{align}\)</p> </li> </ul> <p>The idea between the general form and its update rule is simple</p> <blockquote> <p>Derive an expression to show how the prediction \(\hat{y}(t \mid \theta)\) depends on the model parameters. Then, derive an expression for the gradient \(\psi(t, \theta)\) of \(\hat{y}(t \mid \theta)\) with respect to \(\theta\). These expressions will result in filters that depend on \(\theta\) and utilize observed data as inputs. Subsequently, \(\hat{y}(t)\) and \(\psi(t)\) are obtained from these expressions by replacing past values \(\hat{y}(t-k \mid \theta)\) and \(\psi(t-k, \theta)\) with \(\hat{y}(t-k)\) and \(\psi(t-k)\), respectively, and by substituting \(\theta\) with its most recent estimate.</p> </blockquote> <p>The algorithm \(\ref{eq:quad_criterion_with_general_form:start}\sim\ref{eq:quad_criterion_with_general_form:end}\) aims to minizing the quadratic criterion</p> \[\mathbb{E}\frac{1}{2}\varepsilon(t,\theta)\Lambda_0 \varepsilon(t,\theta)\] <p>where \(\Lambda_0\) is the covariance matrix of the prediction errors. If we instead aim at minimizing the general criterion</p> \[\mathbb{E} l(\varepsilon(t,\theta)),\] <p>the only difference is that \(\hat{\Lambda}^{-1}(t)\varepsilon(t)\) must be repaced by \(l_\varepsilon^T(\varepsilon(t))\), then the updated version is</p> \[\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) l_\varepsilon^T(\varepsilon(t))\right ]_{D_\mathscr{M}}\] <h2 id="users-choice">Users choice</h2> <ol> <li>Model set \(\mathscr{F},\mathscr{G},\mathscr{H}\)</li> <li>Input signal \(\{ u(t)\}\)</li> <li>Criterion function \(l\)</li> <li>Gain sequence \(\{ \alpha(t)\}\)</li> <li>Search direction \(R(t)\)</li> <li>Intial conditions \(\hat{\theta}(0), R(0),\dots\)</li> <li> \[\dots\] </li> </ol>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[A general framework]]></summary></entry><entry><title type="html">Application of General Recursive Framcework to Linear Regression Model</title><link href="https://ruoqizzz.github.io/blog/2024/Application-of-General-Recursive-Framcework-to-Linear-Regression-Model/" rel="alternate" type="text/html" title="Application of General Recursive Framcework to Linear Regression Model"/><published>2024-07-03T18:05:00+00:00</published><updated>2024-07-03T18:05:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Application-of-General-Recursive-Framcework-to-Linear-Regression-Model</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Application-of-General-Recursive-Framcework-to-Linear-Regression-Model/"><![CDATA[<h2 id="application-to-linear-regression-models">Application to Linear Regression Models</h2> <p>Here, we will discuss how a general framework of Recursive System Identification ( <a href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification/">(Part I</a>, <a href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-2/">Part II</a>, <a href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-3/">Part III</a>) can be appliced to a very special case: when the predcition is linear in parameters \(\theta\).</p> <h3 id="the-model-set">The Model Set</h3> <p>The linear prediction can be written as</p> \[\begin{align} \hat{y}(t\vert \theta)=g_\mathscr{M}(\theta;t,z^{t-1})=\phi^T(t)\theta+\mu(t), \label{eq:linear_model} \end{align}\] <p>where \(\phi(t)\) is a \(d\times p\)-dimensional matrix function of \(t\) and \(z^{t-1}\), \(\theta\) is a \(d\times 1\) column vector and \(\mu(t)\) is a knwon \(p\times 1\) column vector function of \(t\) and \(z^{t-1}\).</p> <p>Sometimes we use the model \(\begin{align} \hat{y}(t\vert \theta)=\theta^T\phi(t)+\mu(t), \label{eq:linear_model_mp} \end{align}\) which is different to \(\eqref{eq:linear_model}\). Here \(\theta\) is an \(n'\times p\)-matrix and \(\phi(t)\) is an \(n' \times 1\)-column vector function of \(t\) and \(z^{t-1}\). The \(k\)-th row of \(\eqref{eq:linear_model_mp}\), \(\hat{y}_k(t\vert \theta)=\theta_k^T\phi(t)+\mu_k(t),\) where \(\hat{y}_k(t\vert \theta)\) is the \(k\)-th component of \(\hat{y}\) and \(\theta_k\) is the \(k\)-th column of \(\theta\). This is a linear regression model with paramter vecotor \(\theta_k\) and it is independent to other rows. Thus we can treat this model as a collection of \(p\) indenpendent linear regressions with same regression vector \(\phi(t)\).</p> <p><strong>[Example 1: Linear Difference Equations]</strong></p> <p>Consider a linear difference equations with \(p\)-dimensional output and \(r\)-dimensional input \(u(t)\), \(\begin{align} y(t)+A_1y(t-1) + \dots + A_n y(t-n) = B_1u(t-1)+\dots+B_m u(t-m)+v(t) \label{eq:linear_difference} \end{align}\) Where \(A_i\) are \(p\times p\) unkown matrices, \(B_k\) are \(p\times r\) unkown matrices and \(v(t)\) is a \(p\)-dimensional disturbance term which is usually either of unspecified character or supposed to be a sequence of indenpendent random vectors each of zero mean. A reasonable predictor is given by \(\hat{y}(t\vert \theta)= \theta^T \phi(t),\) with \(\theta^T= \begin{pmatrix} A_1 &amp; \dots &amp; A_n &amp; B_1 &amp; \dots &amp; B_m \end{pmatrix}\\ \phi^T(t)=\begin{pmatrix} -y^T(t-1) &amp; \dots &amp; -y^T(t-n) &amp; u^T(t-1) &amp; \dots &amp; u^T(t-m) \end{pmatrix}.\) where \(\theta^T\) is a \(p\times (np+mr)\)-matrix.</p> <p><strong>[Example 1b: Comcrete Example]</strong></p> <p>\(p=2,n=2,r=1,m=1\): \(\hat{y}(t\vert \theta)= \begin{bmatrix} -y_1(t-1) &amp; -y_2(t-1) &amp; 0 &amp; 0 &amp; -y_1(t-2) &amp; -y_2(t-2) &amp; 0 &amp; 0 &amp; u_1(t-1) &amp; 0\\ 0 &amp; 0 &amp; -y_1(t-1) &amp; -y_2(t-1) &amp; 0 &amp; 0 &amp; -y_1(t-2) &amp; -y_2(t-2) &amp; 0 &amp; u_1(t-1) \end{bmatrix} \begin{bmatrix} a_{11}^{(1)} \\ a_{12}^{(1)} \\ a_{21}^{(1)} \\ a_{22}^{(1)} \\ a_{11}^{(2)} \\ a_{11}^{(2)} \\ a_{21}^{(2)} \\ a_{22}^{(2)} \\ b_{11}^{(2)} \\ b_{21}^{(2)} \\ \end{bmatrix}\) where \(A_k=(a_{ij}^{(k)})\), \(B_k=(b_{ij}^{(k)})\).</p> <p>THe gradient of the model in \(\eqref{eq:linear_model}\) is given by \(\left [ \frac{d}{d\theta} \hat{y}(t\vert \theta) \right ]= \psi(t).\) For linear differnece euations, the stability region is easy to demtermine because only have finite past \(y(t)\) and \(u(t)\), \(D_s = \mathbb{R}^d.\)</p> <h3 id="the-recursive-prediction-error-algorithm">The Recursive Prediction Error Algorithm</h3> <p><a href="https://mitpress.mit.edu/9780262620581/theory-and-practice-of-recursive-identification-3">The general framework of recursive identification</a> can be directlyo applied to model in \(\eqref{eq:linear_model}\) \(\begin{align} &amp;\varepsilon(t) = y(t)-\phi^T(t)\hat{\theta}(t-1)-\mu(t) \\ &amp;\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)]\\ &amp;R(t)=R(t-1)+\alpha(t)[\phi(t)\Lambda^{-1}\phi^T(t) - R(t-1)]\\ &amp;\hat{\theta}(t) = \hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t) \end{align}\)</p> <h3 id="approximate-gradient-the-instrumental-variable-method">Approximate Gradient: The instrumental Variable Method</h3>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid,"/><category term="linear_model"/><summary type="html"><![CDATA[Application to Linear Regression Models]]></summary></entry><entry><title type="html">A general framework of Recursive System Identification (Part III)</title><link href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-3/" rel="alternate" type="text/html" title="A general framework of Recursive System Identification (Part III)"/><published>2024-07-02T18:11:00+00:00</published><updated>2024-07-02T18:11:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-3</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-3/"><![CDATA[<h2 id="a-recursive-prediction-error-identification-algorithm-for-general-critera">A Recursive Prediction Error Identification Algorithm for General Critera</h2> <h3 id="general-criteria">General Criteria</h3> <p>Now let’s consider the general criterion,</p> \[\mathbb{E}_{z^t}l(t, \theta, \varepsilon(t,\theta))\] <p>The recursive minimization of this criterion is entirely analogous to the quadratic criterion.</p> \[\left[ \frac{d}{d\theta}l (t,\theta,\varepsilon(t,\theta))\right]^T = l_\theta^T(t,\theta,\varepsilon(t,\theta))-\psi^T(t,\theta)l_\varepsilon^T(t,\theta,\varepsilon(t,\theta)),\] <p>where</p> \[\varepsilon(t,\theta) = y(t)-\hat{y}(t,\theta)\\ \frac{d}{d\theta}\varepsilon(t,\theta)=\frac{d}{d\theta}[y(t)-\hat{y}(t\vert \theta)=-\psi^T(t,\theta).\] <p>\(l_\theta\) and \(l_\varepsilon\) denotes the partial derivatives with respect to \(\theta\) and \(\varepsilon\). The approach of <a href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-2/">Part II</a> now leads to the algorithm</p> \[\begin{align} \hat{\theta}(t)=\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \left [-l_\theta^T(t,\hat{\theta}(t-1),\varepsilon(t))+\psi^T(t,\theta)l_\varepsilon^T(t,\hat{\theta}(t-1),\varepsilon(t)) \right ] \label{eq:general_stochastic_newton_theta} \end{align}\] <p>If \(l\) only depends on \(\varepsilon\) then \(l_\theta=0\) and</p> \[\hat{\theta}(t)=\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi^T(\theta)l_\varepsilon^T(\varepsilon(t))\] <p>the only difference from qudratic criterion is \(\hat{\Lambda}(t)\varepsilon(t)\) is replaced by \(l_\varepsilon^T(\varepsilon(t))\).</p> <h3 id="general-search-direction">General Search Direction</h3> <p>In \(\eqref{eq:general_stochastic_newton_theta}\) \(R(t)\) is the approximation of Hession of \(V(\theta) = \mathbb{E} l (t,\theta,\varepsilon)\). Then we can get</p> \[\begin{align} R(t)=R(t-1)+\alpha(t) \left[ l_{\theta\theta}(t,\hat{\theta}(t-1),\varepsilon(t))+ \psi(t)l_{\varepsilon\varepsilon}(t,\hat{\theta}(t-1),\varepsilon(t))\psi^T(t) -R(t-1) \right ] \label{eq:general_Rt_update} \end{align}\] <p>where \(l_{\theta\theta}\) and \(l_{\varepsilon\varepsilon}\) are the second derivatives w.r.t \(\theta\) and \(\varepsilon\). This gives a Newton-type updating direction which is known to be efficient in nonlinear programming problems. Of course any other updateing direction forms a sharp angle with the gradient will move \(\hat{\theta}\) downhill on average. This means \(R(t)\) can be any positive deifnite matrix and still ensure the criterion is minimized. Then we can replace \(\eqref{eq:general_Rt_update}\) with</p> \[R(t)=R(t-1)+\alpha(t)H\left( R(t-1),\hat{\theta}(t-1),\varepsilon(t),\psi(t) \right),\] <p>where \(H\) is a function such that the positive definiteness of \(R(t)\) is guaranteed.</p> <h3 id="stochastic-gradient-algorithms">Stochastic Gradient Algorithms</h3> <p>A common choice of \(R(t)\) is a multiple of the identity matirx, which makes the updating direction coincide with the negative gradient of the criterion and written as</p> \[\begin{align} R(t)&amp;=r(t)I,\\ r(t)&amp;=r(t-1) + \alpha(t)\{ \text{tr}[l_{\theta\theta}(t,\hat{\theta}(t-1),\varepsilon(t))+ \psi(t)l_{\varepsilon\varepsilon}(t,\hat{\theta}(t-1),\varepsilon(t))\psi^T(t)] -r(t-1). \} \end{align}\]]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid"/><summary type="html"><![CDATA[A Recursive Prediction Error Identification Algorithm for General Critera]]></summary></entry><entry><title type="html">A general framework of Recursive System Identification (Part II)</title><link href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-2/" rel="alternate" type="text/html" title="A general framework of Recursive System Identification (Part II)"/><published>2024-06-25T14:58:00+00:00</published><updated>2024-06-25T14:58:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-2</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification-2/"><![CDATA[<p>This blog post aims to summarise Chapter 3 of <a href=",https://mitpress.mit.edu/9780262620581/theory-and-practice-of-recursive-identification/">Theory and Practice of Recursive Identification</a> which derives a general recursive identification method that can be applied to any set of (linear) models.</p> <p>To develop a unified approach to recursive identification consists 3 phases：</p> <ol> <li>Define the framework</li> <li>Derive the Algorithm: In the book, the authors mainly focus on <strong>minimizing the prediction error variance recursively</strong>, using the idea from stochastic approximation (See blog post Recursive Least Squares Derived from Stochastic Approximation Approach for details).</li> <li>Apply the Algorithm: We will show how the general algorithm can be applied to a particular model set, <strong>a linear regression model</strong> later.</li> </ol> <p>This is the second part of this blog series, please first see <em><a href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification/">A general framework of Recursive System Identification (Part I): System and Models</a>.</em></p> <h2 id="recursive-gauss-newton-algorithms-for-quadratic-criteria">Recursive Gauss-Newton Algorithms for Quadratic Criteria</h2> <p>Here we will talk about how to derive a recursive algorithm for the estimation of model parameters minimizing a prediction error criterion. The development will lead to basic general algorithm that is the main object of recursive identification.</p> <p>In the spirit of the offline criterion (see blog <em><a href="">Offline Identification</a></em>), we would like to select \(\theta\) such that the criterion</p> \[\mathbb{E}_{z^t}l(t, \theta, \varepsilon(t,\theta))\] <p>where \(z^t = (y(t), u(t))\) gives the current outputs and inputs. This type of criteria can be minimized recursively using the stochastic approximation approach (see blog <em><a href="https://ruoqizzz.github.io/blog/2024/Recursive-Least-Squares-Derived-from-Stochastic-Approximation-Approach/">Recursive Least Squares Derived from Stochastic Approximation Approach</a></em> for details.) For example, for the problem</p> \[\begin{align} \min_x V(x) \\ V(x)=\mathbb{E}_e J(x, e(t)), \end{align}\] <p>it can be recursively minimized by the stochastic Newton method,</p> \[\begin{align} \hat{x}(t)=\hat{x}(t-1) + \alpha(t) \left [ \bar{V}^{''}(\hat{x}(t-1), e(t)) \right]^{-1} Q(\hat{x}(t-1), e(t)), \label{eq:stochastic_newton} \end{align}\] <p>where \(-Q(x,e)\) is the gradient of \(J(x,e)\) with respect to \(x\) and \(\bar{V}^{''}(x,e)\) is some approximation of the second derivative of \(V(x)\) based on the observations up to time \(t\).</p> <p>To be more general, here we assume that the limit</p> \[\bar{E} l(t, \theta, \varepsilon(t,\theta)) \triangleq \lim_{N \rightarrow \infty} l(t, \theta, \varepsilon(t,\theta)) \triangleq \bar{V}(\theta)\] <p>exists.</p> <h3 id="a-general-minimization-algorithm-for-quadratic-criteria">A General Minimization Algorithm for Quadratic Criteria</h3> <p>Here we talk about the special case when \(l\) is quadratic in \(\varepsilon\),</p> \[\begin{align} V(\theta) = \mathbb{E} l (t,\theta,\varepsilon)= \mathbb{E} \frac{1}{2}\varepsilon^T(t,\theta)\Lambda^{-1}\varepsilon^T(t,\theta). \label{eq:V} \end{align}\] <p>Here we have</p> \[\left[ \frac{d}{d\theta}l (t,\theta,\varepsilon)\right]^T=-\psi(t,\theta)\Lambda^{-1}\varepsilon(t,\theta)\] <p>where</p> \[\frac{d}{d\theta}\varepsilon(t,\theta)=\frac{d}{d\theta}[y(t)-\hat{y}(t\vert \theta)=-\psi^T(t,\theta).\] <p>Let’s denote the second-derivative approximation \(\bar{V}^{''}(x,e)\) by \(R(t)\), the algorithm \(\eqref{eq:stochastic_newton}\) becomes,</p> \[\begin{align} \hat{\theta}(t)=\hat{\theta}(t-1) + \alpha(t) R^{-1} \psi(t,\hat{\theta}(t-1)\Lambda^{-1}\varepsilon(t,\hat{\theta}(t-1)). \label{eq:stochastic_newton_theta} \end{align}\] <p>The quantities \(\psi(t,\hat{\theta}(t-1)\) and \(\varepsilon(t,\hat{\theta}(t-1))\) can be computed using</p> \[\begin{align} \xi (k+1, \hat{\theta}(t-1)) &amp;= A(\hat{\theta}(t-1) \xi (k, \hat{\theta}(t-1)) + B(\hat{\theta}(t-1))z(k),\\ k&amp;=0,1,\dots,t-1, \xi(0, \hat{\theta}(t-1))=\xi_0\\ \begin{pmatrix}\hat{y}(t\vert \hat{\theta}(t-1))\\ \text{col}~\psi(t,\hat{\theta}(t-1)) \end{pmatrix}&amp;=C(\hat{\theta}(t-1))\xi(t,\hat{\theta}(t-1))\\ \varepsilon(t,\hat{\theta}(t-1))&amp;=y(t)-\hat{y}(t\vert \hat{\theta}(t-1)) \label{eq:newton-kalman} \end{align}\] <p>The problem here is that \(\eqref{eq:newton-kalman}\) is not recursive in general. To compute \(\xi (k+1, \hat{\theta}(t-1))\), we need the data from \(z(0)\) to \(z(t-1)\). It can be solved by first rewrite \(\xi (k+1, \hat{\theta}(t-1))\).</p> \[\xi (k+1, \hat{\theta}(t-1)) = [A(\hat{\theta}(t-1)]^t\xi_0 + \sum_{k=0}^{t-1}[A(\hat{\theta}(t-1)]^{t-k-1}B(\hat{\theta}(t-1)z(k).\] <p>If \(\hat{\theta}(t-1)\in D_s\) where \(D_s=\{ \theta \vert A(\theta) \text{ has all eigenvalues strictly inside the unit circle} \}\), then the factor \([A(\hat{\theta}(t-1)]^t\) tends to zero exponentially. Consequently, the sum is dominated by the last terms \(k=t-K, t-K+1, \dots, t-1\) for some value \(K\). Also since \(\alpha(t)\) is a small number for large \(t\), the difference between \(\hat{\theta}(t-1)\) and \(\hat{\theta}(t-K)\) will be quite small for large \(t\). Combining these two factors,</p> \[\xi(t, \hat{\theta}(t-1)) \approx \xi(t) \triangleq \sum_{k=1}^{t-1} \left [ \sum_{s=k+1}^{t-1}A(\theta({\hat{s}))} \right] B( \hat{\theta}(k)z(k)\] <p>Then \(\xi(t)\) can be computed recursively without all history data</p> \[\begin{align} \xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t). \label{eq:recursive_xi} \end{align}\] <p>Based on this,</p> \[\begin{pmatrix} \hat{y}(t | \hat{\theta}(t-1)) \\ \text{col } \psi(t, \hat{\theta}(t-1)) \end{pmatrix} \approx \begin{pmatrix} \hat{y}(t) \\ \text{col } \psi(t) \end{pmatrix} \triangleq C(\hat{\theta}(t-1)) \xi(t).\] <p>and</p> \[\begin{align} \varepsilon(t, \hat{\theta}(t-1)) \approx \varepsilon(t) = y(t) - \hat{y}(t). \label{eq:recursive_epsilon} \end{align}\] <p>These gives</p> \[\hat{\theta}(t) = \hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t).\] <p>This show shows that by using the approximations and understanding that the influence of older data diminishes exponentially, we can reformulate the original algorithm into a truly recursive one. This allows us to compute the required terms at each time step efficiently without needing the full history of data, thus making the algorithm more practical and computationally efficient.</p> <h3 id="the-gauss-newton-search-direction">The Gauss-Newton Search Direction</h3> <p>Let’s discuss how to choose \(R(t)\).</p> <p>The Hessian of \(V(\theta)\) in \(\eqref{eq:V}\) is given by \(\frac{d^2}{d\theta^2} V(\theta) = \frac{d^2}{d\theta^2} \mathbb{E} \frac{1}{2}\varepsilon^T(t,\theta)\Lambda^{-1}\varepsilon^T(t,\theta) \\ = \mathbb{E}\frac{d}{d\theta} -\varepsilon(t,\theta) \Lambda^{-1}\psi^T(t, \theta)\\ = \mathbb{E}\psi(t, \theta)\Lambda^{-1}\psi^T(t, \theta) + \mathbb{E} \left \{ \left [ \frac{d^2}{d\theta^2} \varepsilon^T(t,\theta) \right ] \Lambda^{-1} \varepsilon(t,\theta) \right \}.\)</p> <p>Here the second derivative of \(\varepsilon\) is a matrix whose \(i,j\)-component is given by</p> \[\mathbb{E} \sum_{k,l=1}^p \left[ \frac{d}{d\theta_i}\frac{d}{d\theta_j} \varepsilon_k(t,\theta)\right](\Lambda^{-1})_{kl}\varepsilon_l(t,\theta).\] <p><strong>[Example]</strong></p> \[\varepsilon(t, \theta) = \begin{pmatrix} \varepsilon_1(t, \theta) \\ \varepsilon_2(t, \theta) \end{pmatrix}\] <p>The first derivative of \(\varepsilon(t, \theta)\) with respect to \(\theta\) is:</p> \[\frac{\partial \epsilon(t, \theta)}{\partial \theta} = \begin{pmatrix} \frac{\partial \varepsilon_1(t, \theta)}{\partial \theta_1} &amp; \frac{\partial \varepsilon_1(t, \theta)}{\partial \theta_2} \\ \frac{\partial \varepsilon_2(t, \theta)}{\partial \theta_1} &amp; \frac{\partial \varepsilon_2(t, \theta)}{\partial \theta_2} \end{pmatrix} = \begin{pmatrix} t &amp; 2\theta_2 \\ t \cos(\theta_1 t) &amp; 1 \end{pmatrix}\] <p>Second Derivative of \(\varepsilon(t, \theta)\):</p> <p>For \(\varepsilon_1(t, \theta) = \theta_1 \cdot t + \theta_2^2\),</p> \[\frac{\partial^2 \varepsilon_1(t, \theta)}{\partial \theta_1^2} = 0, \quad \frac{\partial^2 \varepsilon_1(t, \theta)}{\partial \theta_1 \partial \theta_2} = 0\\ \frac{\partial^2 \varepsilon_1(t, \theta)}{\partial \theta_2 \partial \theta_1} = 0, \quad \frac{\partial^2 \varepsilon_1(t, \theta)}{\partial \theta_2^2} = 2\] <p>For \(\varepsilon_2(t, \theta) = \sin(\theta_1 \cdot t) + \theta_2\)</p> \[\frac{\partial^2 \varepsilon_2(t, \theta)}{\partial \theta_1^2} = -t^2 \sin(\theta_1 t), \quad \frac{\partial^2 \varepsilon_2(t, \theta)}{\partial \theta_1 \partial \theta_2} = 0 \\ \frac{\partial^2 \varepsilon_2(t, \theta)}{\partial \theta_2 \partial \theta_1} = 0, \quad \frac{\partial^2 \varepsilon_2(t, \theta)}{\partial \theta_2^2} = 0\] <p>So, the second derivative tensor is:</p> \[\begin{pmatrix} \frac{\partial^2 \varepsilon_1}{\partial \theta_1^2} &amp; \frac{\partial^2 \varepsilon_1}{\partial \theta_1 \partial \theta_2} \\ \frac{\partial^2 \varepsilon_1}{\partial \theta_2 \partial \theta_1} &amp; \frac{\partial^2 \varepsilon_1}{\partial \theta_2^2} \end{pmatrix} , \begin{pmatrix} \frac{\partial^2 \varepsilon_2}{\partial \theta_1^2} &amp; \frac{\partial^2 \varepsilon_2}{\partial \theta_1 \partial \theta_2} \\ \frac{\partial^2 \varepsilon_2}{\partial \theta_2 \partial \theta_1} &amp; \frac{\partial^2 \varepsilon_2}{\partial \theta_2^2} \end{pmatrix} = \begin{pmatrix} 0 &amp; 0 \\ 0 &amp; 2 \end{pmatrix} , \begin{pmatrix} -t^2 \sin(\theta_1 t) &amp; 0 \\ 0 &amp; 0 \end{pmatrix}\] <p>Suppose that there exists a value \(\theta_\circ \in \mathcal{D}_\mathscr{M}\) that gives a correct description of the system, so that \(\{\varepsilon(t, \theta)\}\) is a sequence of independent random vectors each of zero mean. This implies that \(\varepsilon(t, \theta_\circ)\) is independent of \(z^{t-1}\) and hence of</p> \[\frac{d}{d\theta_i}\frac{d}{d\theta_j}\varepsilon(t,\theta) = \frac{d}{d\theta_i}\frac{d}{d\theta_j} [y(t)-g_\mathscr{M}(\theta;t,z^{t-1})]\\ =-\frac{d}{d\theta_i}\frac{d}{d\theta_j}g_\mathscr{M}(\theta;t,z^{t-1}).\] <p>At the true minimum \(\theta_\circ\),</p> \[\mathbb{E} \left \{ \left [ \frac{d^2}{d\theta^2} \varepsilon^T(t,\theta) \right ] \Lambda^{-1} \varepsilon(t,\theta) \right \}=0\] <p>Then a suitable approximation of Heesion is</p> \[\frac{d^2}{d\theta^2} V(\theta) = \mathbb{E}\psi(t, \theta)\Lambda^{-1}\psi^T(t, \theta)\] <p>This approximation is good when close to the minimum where a true Hessian is more important than elsewhere. With an approximation of the Hessian, the algorithms are often referred to the Gauss-Newton direction.</p> <p>A natural approximation of Hession at \(\theta=\hat{\theta}(t-1)\), based on the observation \(z^{t}\) is then obtained by</p> \[\begin{align} R(t)=\frac{1}{t} \sum_{k=1}^t \psi(k, \hat{\theta}(t-1))\Lambda^{-1}\psi^T(k, \hat{\theta}(t-1)). \label{eq:rt} \end{align}\] <p>This is not recursive because \(\psi(k, \hat{\theta}(t-1))\) can not be computed recursively. Then we have to use</p> \[\begin{align} R(t)=\frac{1}{t} \sum_{k=1}^t \psi(k)\Lambda^{-1}\psi^T(k). \label{eq:app_rt} \end{align}\] <p>where \(\psi(k)\) are determined as … However, since the first terms of sum in \(\eqref{eq:app_rt}\) are computed for parameter estimates far from \(\hat{\theta}(t-1)\), \(\eqref{eq:app_rt}\) is usually not a good approximation of \(\eqref{eq:rt}\). It is better to use a weighted mean where more weight is put on the last values</p> \[\begin{align} R(t)=\frac{1}{t} \sum_{k=1}^t \beta(t,k)\psi(k)\Lambda^{-1}\psi^T(k)+\delta(t)R_0 \label{eq:app_rr} \end{align}\] <p>where \(\delta(t)+\sum_{k=1}^t \beta(t,k)=1\). Also, we can added some prior infomation in \(R_0\). We can also write this in a recursive way</p> \[R(t)=R(t-1)+\alpha(t)[\psi(t)\Lambda^{-1}\psi^T(t) - R(t-1)], R(0)=R_0.\] <p>When \(\alpha(t)\) is chosen larger than \(1/t\), we put more weight on recent measurements.</p> <h3 id="the-choice-of-weighting-matrix">The choice of Weighting Matrix</h3> <p>When the system has scalar output, then a constant \(\Lambda\) acts only as scaling factor. For a multioutput system, the choice of \(\Lambda\) will affect the accuracy of the estimates. The optimal choice is the covariance matrix of the true prediction errors</p> \[\Lambda_\circ = \mathbb{E}[\varepsilon(t,\theta_\circ)\varepsilon^{T}(t,\theta_\circ) ]\] <p>which gives the smallest covariance matrix of the parameter estimates in the offline case. Since \(\Lambda_\circ\) is usually ubnknown, a reasonable choice of \(\Lambda\),</p> \[\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)].\] <h3 id="projection-into-the-stability-region">Projection into the Stability Region</h3> <p>The model \(\mathscr{M}\) is obtained as \(\theta\) ranges over the set \(\mathcal{D}_\mathscr{M}\). The generation of prediction is stable only for \(\theta\in \mathcal{D}_s\) where</p> \[\begin{align} D_{s}=\{ \theta \vert \mathscr{F}(\theta) \text{ has all eigenvalues strictly inside the unit circle} \}. \label{eq:Ds} \end{align}\] <p>In fact, in the derivation of the algorithm, we used an assumption that \(\hat{\theta}(t)\in D_{s}\) to adjust \(\xi\) and \(\varepsilon\) in \(\eqref{eq:recursive_xi}\) and \(\eqref{eq:recursive_epsilon}\). This can be accomplished by a project facility of the type</p> \[\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}},\] <p>where</p> \[\begin{align} \left [x \right ] _{D_\mathscr{M}}= \left \{\begin{array}{lr} x &amp; \text{if }x \in {D_\mathscr{M}}\\ \text{a value strctily interior to }{D_\mathscr{M}} \text{ if } x \notin {D_\mathscr{M}} \end{array} \right. \end{align}\] <h3 id="summary-of-the-algorithm">Summary of the Algorithm</h3> <p>Now we can summarize the general algorihtm for minizing the quadratic criterion.</p> \[\begin{align} &amp;\varepsilon(t) = y(t)-\hat{y}(t) \\ &amp;\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)]\\ &amp;R(t)=R(t-1)+\alpha(t)[\psi(t)\Lambda^{-1}\psi^T(t) - R(t-1)]\\ &amp;\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}}\\ &amp;\xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t)\\ &amp;\begin{pmatrix} \hat{y}(t) \\ \text{col } \psi(t) \end{pmatrix} = C(\hat{\theta}(t-1)) \xi(t). \label{eq:algo_summary_quad} \end{align}\] <h3 id="equivalent-rerrangement">Equivalent Rerrangement</h3> <p>Introduce</p> \[P(t)=\alpha(t)R^{-1}(t).\] <p>Then,</p> \[P(t)=\frac{1}{\gamma(t)}\left\{ P(t-1)-P(t-1)\psi(t)[\psi^T(t)P(t-1)\psi(t)+\gamma(t)\hat{\Lambda}(t) ]^{-1}\psi^T(t)P(t-1), \right \}\] <p>where</p> \[\gamma(t)=\alpha(t-1)[1-\alpha(t-1)]/\alpha(t-1).\] <p>Using this expression we can write</p> \[\begin{align} L(t)&amp;\triangleq \alpha(t)R^{-1}(t)\psi(t)\hat{\Lambda}^{-1}(t)\\ &amp;=P(t)\psi(t)\hat{\Lambda}^{-1}(t)\\ &amp;=P(t-1)\psi(t)[\psi^T(t)P(t-1)\psi(t)+\gamma(t)\hat{\Lambda}(t) ]^{-1}. \end{align}\] <p>Hence the algorithm can be rewriiten as</p> \[\begin{align} &amp;\varepsilon(t) = y(t)-\hat{y}(t) \\ &amp;\hat{\Lambda}(t) = \hat{\Lambda}(t-1) + \alpha(t)[\varepsilon(t)\varepsilon^T(t) - \hat{\Lambda}(t-1)]\\ &amp;S(t)= \psi^T(t)P(t-1)\psi(t)+\gamma(t)\hat{\Lambda}(t)\\ &amp;L(t)=P(t-1)\psi(t)S^{-1}(t)\\ &amp;\hat{\theta}(t) = \left [\hat{\theta}(t-1) + \alpha(t) R^{-1}(t) \psi(t) \Lambda^{-1} \varepsilon(t)\right ]_{D_\mathscr{M}}\\ &amp;P(t)=[P(t-1)-L(t)S(t)L^T(t)]/\gamma(t)\\ &amp;\xi (t+1)= A(\hat{\theta}(t))\xi(t) + B(\hat{\theta}(t))z(t)\\ &amp;\begin{pmatrix} \hat{y}(t) \\ \text{col } \psi(t) \end{pmatrix} = C(\hat{\theta}(t-1)) \xi(t). \label{eq:algo_summary_quad2} \end{align}\]]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid"/><summary type="html"><![CDATA[This blog post aims to summarise Chapter 3 of Theory and Practice of Recursive Identification which derives a general recursive identification method that can be applied to any set of (linear) models.]]></summary></entry><entry><title type="html">A general framework of Recursive System Identification (Part I)</title><link href="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification/" rel="alternate" type="text/html" title="A general framework of Recursive System Identification (Part I)"/><published>2024-06-19T12:05:00+00:00</published><updated>2024-06-19T12:05:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/A-general-framework-of-Recursive-System-Identification/"><![CDATA[<p>This blog post aims to summarise Chapter 3 of <a href=",https://mitpress.mit.edu/9780262620581/theory-and-practice-of-recursive-identification/">Theory and Practice of Recursive Identificatio</a> which derives a general recursive identification method that can be applied to any set of (linear) models.</p> <p>To develop a unified approach to recursive identification consists 3 phases：</p> <ol> <li>Define the framework</li> <li>Derive the Algorithm: In the book, the authors mainly focus on <strong>minimizing the prediction error variance recursively</strong>, using the idea from stochastic approximation (See blog post Recursive Least Squares Derived from Stochastic Approximation Approach for details).</li> <li>Apply the Algorithm: We will show how the general algorithm can be applied to a particular model set, <strong>a linear regression model</strong> later.</li> </ol> <h2 id="part-i-systems-and-models">Part I: Systems and Models</h2> <h3 id="systems">Systems</h3> <p>The system is the physical object that generates the obverations, the output signals \(\{y_t\}\) where \(t\) is a discrete time index and \(y_t\) is a \(p\)-dimensional column vector. Many systems also have a measure input signals \(\{u_t\}\) with dim \(r\), which can be chosen by the user. To get a reasonable identification results of the system, some properties of the inputs are required. In loose term, the input should excite all modes of system, called “persistenly exciting”. Let \(\{u_t\}\) be such that the limits</p> \[\lim_{N\rightarrow\infty}\frac{1}{N}\sum_{t=1}^Nu(t)u^T(t-j)\triangleq r(j)\] <p>exist for all \(0\leq j\leq n\). The block matrix \(R_m\) whose \(i,k\) entry is \(r(i-k)\). The inputs \(\{u_t\}\) is said to be <em>persistently exciting of order \(n\)</em>, if \(R_n\) is nonsigular.</p> <h3 id="models">Models</h3> <p>A model is a link between the past oservations and the unknown future. At time \(t-1\), with the observations, the input-output data \(z(t) = \begin{pmatrix} y(t) \\ u(t) \end{pmatrix}, (z^t = (z(0) \ldots z(t))\), it is possible to predict the output at time \(t\) with a model, \(\hat{y}(t\vert \theta)=g_\mathscr{M}(\theta;t,z^{t-1})\)</p> <p>Here, for a fixed \(\theta\), \(g_\mathscr{M}(\theta;\cdot,\cdot)\) is a determistic function from \(\mathbb{R}\times \mathbb{R}^{t(r+p)}\) to \(\mathbb{R}^p\) and its parameter \(\theta\) is a vector of dim \(d\). The model is denoted by \(\mathscr{M}(\theta)\). The set of models condered will be obtained as \(\theta\) ranges over a subset \(\mathscr{D}_\mathscr{M}\) of \(\mathbb{R}^d\),</p> \[\mathscr{M}=\{\mathscr{M} \vert \theta \in \mathscr{D}_\mathscr{M}\}.\] <p><strong>[Example: linear predictor models]</strong> \(\begin{align} \phi(t+1,\theta) &amp;= \mathscr{F}(\theta)\phi(t,\theta)+\mathscr{G}(\theta)z(t)\\ \hat{y}(t\vert \theta)&amp;=\mathscr{H}(\theta)\phi(t,\theta) \label{eq:linear_predictor} \end{align}\)</p> <p>where \(\mathscr{F},\mathscr{G},\mathscr{H}\) are matrix functions of \(\theta\).</p> <p><strong>[Example: nonlinear predictor models]</strong> \(\phi(t+1,\theta) = f(\theta;t,\phi(t,\theta),z(t))\\ \hat{y}(t\vert \theta)=h(\theta;t,\phi(t,\theta))\)</p> <p>For the linear predictor models \(\eqref{eq:linear_predictor}\), we assume that the model is differentiable with respect to $$\theta$,</p> \[\left [ \frac{d}{d\theta}\hat{y}(t\vert \theta) \right ]^T=\psi(t,\theta)\] <p>where \(\psi(t,\theta)\) is a \(d\times p\)-matrix and can be formed from \(z^{t}\) by a finite-dimension filter by introducing</p> \[\zeta(t,\theta)=(\phi^{(1)}(t,\theta)~\cdots~\phi^{(d)}(t,\theta)~~~\text{(a }d\times n~\text{matrix)}\] <p>where the superscript \((i)\) denotes diferentiation with respect to \(\theta_i\). Since \(\mathscr{F}(\theta)\) is a matrix and \(\theta\) is a vector, the derivative of \(\mathscr{F}(\theta)\) is a tensor (a quantity with three indices). To simplify the notaiton, we introduce</p> \[\left [ \frac{d}{d\theta}\mathscr{F}(\theta)\phi+\mathscr{G}(\theta)z \right ]^T= M(\theta,\psi,z)\\ \left [ \frac{d}{d\theta}\mathscr{H}(\theta)\phi \right ]^T= D(\theta,\psi,z)\\\] <p>For \(M(\theta,\psi,z)\), its \(i\)-th column is</p> \[\left [ \frac{d}{\partial \theta_i}\mathscr{F}(\theta) \right ]\phi+ \left [ \frac{d}{\partial \theta_i}\mathscr{G}(\theta) \right ]z\] <p>Then,</p> \[\begin{align} \zeta(t+1,\theta)&amp;=\mathscr{F}\zeta(t,\theta) + M(\theta,\phi(t,\theta),z(t)) \\ \psi^T(t,\theta)&amp;=\mathscr{H}\zeta(t,\theta)+D(\theta,\phi(t,\theta)). \label{eq:linear_predictor_d} \end{align}\] <p>z theoretical considerations, it is more convenient to collect \(\eqref{eq:linear_predictor}\) and \(\eqref{eq:linear_predictor_d}\) into one filter with \(z(t)\) as input and \(\hat{y}(t\vert \theta)\) and \(\psi(t,\theta)\) as output. Let’s introduce a state vector</p> \[\xi (t,\theta) = \begin{pmatrix}\phi(t,\theta)\\ \text{col}~\zeta(t,\theta) \end{pmatrix}\] <p>where \(\text{col} A\) here, it means a column vector constructed from the matrix \(A\) by stacking its columns under each other. Similarly, we can introduce the output vector</p> \[\begin{pmatrix}\hat{y}(t\vert \theta)\\ \text{col}~\psi(t,\theta) \end{pmatrix}.\] <p>We can now rewrite \(\eqref{eq:linear_predictor}\) and \(\eqref{eq:linear_predictor_d}\) for some matrices \(A(\theta), B(\theta), \text{and}~C(\theta),\) as</p> \[\begin{align} \xi (t+1, \theta) = A(\theta) \xi (t, \theta) + B(\theta)z(t),\\ \begin{pmatrix}\hat{y}(t\vert \theta)\\ \text{col}~\psi(t,\theta) \end{pmatrix}=C(\theta)\xi(t,\theta) \end{align}\] <p>We can see that \(A(\theta)\) is a matrix with dimension \((d+1)n\times (d+1)n\) matrix and it containt the matrix \(\mathscr{F}(\theta)\) in each of its \(d+1\) block-diagnoal entries and has all zeros above the block diagonal.</p> \[A(\theta) = \begin{pmatrix} \mathscr{F}(\theta) &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; \mathscr{F}(\theta) &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; \mathscr{F}(\theta) \end{pmatrix}\] <p>Hence \(A(\theta)\) has the same eigenvalues as \(\mathscr{F}(\theta)\) but with higher multiplicities. The stability of \(A(\theta)\) there coincide with those of \(\mathscr{F}(\theta)\) . Let us introduce the set</p> \[\begin{align} D_{s}=\{ \theta \vert \mathscr{F}(\theta) \text{ has all eigenvalues strictly inside the unit circle} \}. \label{eq:Ds} \end{align}\] <p><strong>[Example: A difference Equation Model]</strong></p> <p>For the difference equation</p> \[\begin{align} y(t)+a_1y(t-1) + \dots + a_n y(t-n) = b_1u(t-1)+\dots+b_mu(t-m)+v(t) \label{eq:linear} \end{align}\] <p>we may take</p> \[\phi^T(t, \theta)=\begin{bmatrix} -y(t-1) &amp;\dots -y(t-n)&amp;u(t-1)&amp;\dots u(t-m) \end{bmatrix}\] <p>which is actually independent of \(\theta\). The matrix in</p> \[\begin{aligned} &amp; \mathscr{F}(\theta) = \left( \begin{array}{cccc|cccc} 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; 0 &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ \hline 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1 \\ \end{array} \right) \leftarrow \text{row } n + 1,\\ &amp; \mathscr{G}(\theta)=\left(\begin{array}{rr} -1 &amp; 0 \\ 0 &amp; 0 \\ \vdots &amp; \vdots \\ 0 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 0 \\ \vdots &amp; \vdots \\ 0 &amp; 0 \end{array}\right) \leftarrow \text { row } n+1 \text {, } \\ &amp; z(t)=\binom{y(t)}{u(t)} \text {, } \\ &amp; \mathscr{H}(\theta)=\theta^{\mathrm{T}}, \\ &amp; \end{aligned}\] <p>For the gradient,</p> \[\phi^{(i)}(t,\theta)=0,~~\psi(t,\theta)=\phi(t,\theta)\] <p>The matrix \(\mathscr{F}(\theta)\) is a lower triangular with zeros along its diagonal and thus its eigenvalues are all zeros. Thus the set \(\eqref{eq:Ds}\) is equal to \(\mathbb{R}^d\).</p>]]></content><author><name></name></author><category term="control"/><category term="recursive_sysid"/><summary type="html"><![CDATA[This blog post aims to summarise Chapter 3 of Theory and Practice of Recursive Identificatio which derives a general recursive identification method that can be applied to any set of (linear) models.]]></summary></entry><entry><title type="html">Offline Identification</title><link href="https://ruoqizzz.github.io/blog/2024/Offline-Identification/" rel="alternate" type="text/html" title="Offline Identification"/><published>2024-06-19T12:05:00+00:00</published><updated>2024-06-19T12:05:00+00:00</updated><id>https://ruoqizzz.github.io/blog/2024/Offline%20Identification</id><content type="html" xml:base="https://ruoqizzz.github.io/blog/2024/Offline-Identification/"><![CDATA[<h2 id="aspects-of-offline-identification">Aspects of Offline Identification</h2> <p>Offline identification is to identify a model of a system using data that has been collected and stored beforehand. For simplicity, we define \(z^{t}=[y(t)^T, u(t)^T]^T\) as the data at the time step \(t\) and \(\{y_t\}, \{u_t\}\) are output and input signals. Offline identification is a wide subject. Here we only try to point out some aspects that have useful implications for recursive identification</p> <h3 id="identification-as-criterion-minimization">Identification as Criterion Minimization</h3> <p>Given a prediction model,</p> \[\hat{y}(t\vert \theta)=g_\mathscr{M}(\theta;t,z^{t-1})\] <p>a natural measure of its validity is the prediction error,</p> \[\varepsilon(t,\theta)=y(t)-\hat{y}(t\vert \theta)\] <p>Since \(\varepsilon(t,\theta)\) is a \(p\)-dimensional vector, it is useful to introduce a scalar measure</p> \[l(t,\theta,\varepsilon(t,\theta))\] <p>where \(l(\cdot,\cdot,\cdot)\) is a function from \(\mathbb{R}\times \mathbb{R}^d \times \mathbb{R}^p\) to \(\mathbb{R}\). With stored data up to time \(t\), a natural criterion of the validity of the model \(\mathscr{M}(\theta)\) is</p> \[V_N(\theta, z^{N})=\frac{1}{N}\sum_{t=1}^N l (t,\theta, \varepsilon(t,\theta)).\] <p>The offline estimate, denoted by \(\hat{\theta}_N\) is obtained by minimization of \(V_N(\theta, z^{N})\) over \(\theta \in \mathcal{D}_\mathscr{M}\).</p> <h3 id="choices-of-criterion">Choices of Criterion</h3> <h4 id="a-quadratic-criterion">A Quadratic Criterion</h4> <p>Quadratic criterion is a natural way of measuring the size of the prediction error,</p> \[\begin{align} l(t,\theta,\varepsilon) = \frac{1}{2}\varepsilon^T\Lambda^{-1}\varepsilon \label{eq:quad_criterion} \end{align}\] <p>where \(\Lambda\) is a positive definite matrix. A possible disadvantage is that it gives substantial penalties for large errors which might lead to sensitivity to outliers. One simple and common way in system identification is to filter all data before processing.</p> <h4 id="the-maximum-likelihood-criterion">The Maximum Likelihood Criterion</h4> <p>Here we assume that \(\varepsilon(t,\theta)\) is a sequence of independent random vectors and its probability density function is \(\bar{f}(t, \theta, x)\) such that</p> \[P(\varepsilon(t,\theta)\in \mathcal{B}) = \int_\mathcal{B} \bar{f}(t, \theta, x) dx.\] <p>The output at time \(t\) can be written as</p> \[y(t) = g_\mathscr{M}(\theta;t,z^{t-1}) + \varepsilon (t,\theta).\] <p>Under the assumption, we can write the conditional probability density function of \(y(t)\) given \(z^{t-1}\) as</p> \[f(\theta; x_t \vert z^{t-1})=P\left ( y(t)=x_t \vert z^{t-1}, \theta \right) = \bar{f}(t, \theta, y_t-g_\mathscr{M}(\theta;t,z^{t-1})).\] <p>Using Bayes’s rule, the joint density function of \(y(t)\) and \(y(t-1)\) given \(z^{t-2}\) can be expressed as</p> \[\begin{align} f(\theta; x_t, x_{t-1} \vert z^{t-2})&amp;=P\left ( y(t)=x_t, y(t-1)=x_{t-1} \vert z^{t-2}, \theta \right) \\ &amp;= P\left ( y(t)=x_t \vert y(t-1)=x_{t-1} ,z^{t-2}, \theta \right) \cdot P\left ( y(t-1)=x_{t-1} \vert z^{t-2}, \theta \right) \\ &amp;= P\left ( y(t)=x_t \vert z^{t-1}, \theta \right) \cdot P\left ( y(t-1)=x_{t-1} \vert z^{t-2}, \theta \right) \\ &amp;= \bar{f}(t, \theta, y_t-g_\mathscr{M}(\theta;t,z^{t-1})) \cdot \bar{f}(t-1, \theta, y_{t-1}-g_\mathscr{M}(\theta;t-1,z^{t-2})) . \end{align}\] <p>Here we assume that \(\{u^t\}\) is a deterministic sequence. Iterating the foregoing expression from \(t=N\) to \(t=1\) gives the joint probability density of \(y(N), y(N-1),\dots,y(1): f(\theta; x_t, x_{t-1},\dots,x_1)\). By replacing the dummy variables \(xc_i\) with corresponding \(y(i)\), we can obtain</p> \[\log (\theta;y(N), y(N-1),\dots,y(1)) = \sum_{t=1}^N \log \bar{f}(t,\theta,\varepsilon(t,\theta)).\] <p>With \(l(t,\theta,\varepsilon)=-\log\bar{f}(t,\theta,\varepsilon)\), \(\hat{\theta}_N\) equals the maximum likelihood estimate (MLE).</p> <p>If we assume that \(\varepsilon\) has a Gaussian distribution with zero mean and covariance matrix \(\Lambda_t(\theta)\) the</p> \[\begin{align} l(t,\theta,\varepsilon)&amp;=-\log f(t,\theta, \varepsilon)\\ &amp;=\frac{p}{2}\log2\pi + \frac{1}{2}\log \det \Lambda_t(\theta)+\frac{1}{2}\varepsilon^T\Lambda_t^{-1}\varepsilon. \label{eq:loss_log} \end{align}\] <p>Here if \(\Lambda_t\) is known and independent of \(\theta\), the we obtain the quadratic criterion as in \(\eqref{eq:quad_criterion}\).</p> <p><strong>[Relationship of MLE and MAP]</strong></p> <p>MLE and Bayesian maximum a posteriori estimate (MAP) are closely related. Using Bayes’s rule,</p> \[P(\theta \vert y^N)=\frac{P(y^N \vert \theta )P(\theta)}{P(y^N)}\] <p>where \(P(y^N \vert \theta )\) is the likelihood function and \(P(\theta)\) is the prior distribution while \(P(y^N)\) is independent of \(\theta\). Thus, the MAP estimate differs from the MLE estimate only via the prior distribution.</p> <h3 id="asymptotic-properties-of-the-offline-estimate">Asymptotic Properties of the Offline Estimate</h3> <p>Some of the results without proof are from <a href="https://ieeexplore.ieee.org/abstract/document/1101840/">Ljung (1978c)</a> and <a href="https://ieeexplore.ieee.org/abstract/document/4046253/">Ljung and Caines (1979)</a>.</p> <p>Suppose that the limit</p> \[\bar{V}(\theta)=\lim_{N\rightarrow \infty}\mathbb{E} V_N(\theta,z^N)\] <p>exists, where \(\mathbb{E}\) is the expectation operator with respect to \(z^N\), The function \(\bar{V}(\theta)\) thus is the expected value of the criterion for a certain fixed \(\theta\). Then, under weak regularity conditions,</p> \[\hat{\theta}_N \text{ converges w.p. to } \theta^* \text{ a minimum of } \bar{V}(\theta)\] <p>as \(N\) tends to infinity. Notice that this is true whether or not the model set \(\mathscr{M}\) contains the true model. Moreover, if \(\hat{\theta}_N\) converges to \(\theta^*\), such that the matrix \(d^2\bar{V}(\theta^*)/d\theta^2\) is incertible, then</p> \[\sqrt{N}(\hat{\theta}_N -\theta^*)\rightarrow \mathcal{N}(0,P),\] <p>where</p> \[\begin{align} P=[\bar{V}^{''}(\theta^*)]^{-1} \left \{ \lim N \cdot \mathbb{E}[\bar{V}^{}(\theta^*, z^N)]^T \bar{V}^{'}(\theta^*, z^N) \right \} [\bar{V}^{''}(\theta^*)]^{-1} \label{eq:app_P} \end{align}\] <p>where \('\) and \(''\) denotes differentiation once and twice, respectively with respect to \(\theta\).</p> <h3 id="relation-to-cramér-rao-bound">Relation to Cramér-Rao Bound</h3> <p>Suppose there is a value \(\theta_\circ\) in the model set such that with \(\theta=\theta_\circ\) gives a correct description of the true data. Then it can be shown that \(\theta^*=\theta_\circ\) and that the matrix P in \(\eqref{eq:app_P}\) equals the Cramer-Rao lower bound provided that \(l\) is chosen as in \(\eqref{eq:loss_log}\).</p> <h4 id="cremer-rao-bound-and-properties-of-estimators">[Cremer-Rao Bound and properties of estimators]</h4> <p>Consider a random vector in \(\mathbb{R}^n\), \(y^n = \begin{pmatrix} y(1) &amp; y(2) &amp;\dots &amp;y(n) \end{pmatrix}\). Let its joint density function be</p> \[f(\theta; x_1,\dots,x_n) = f(\theta;x^n), \label{eq:f_density}\] <p>which is known up to a finite-dimensional parameter vector \(\theta\) with dimension \(d\). The problem we face is to find an estimate of \(\theta\) based on a sample of \(y^n\).<br/> There are certain properties of estimators are desirable. We shall drop the supercrip \(n\) in \(y^n\) when not essential.</p> <p><strong>[Unbiased]</strong></p> <p>An estimator is thus said to be <em>unbiasd</em> if</p> \[\mathbb{E}_\theta \hat{\theta}(y^n) = \theta\] <p>i.e., if its expected value is the true parameter value. For an unbiased estimator, it is of interest to know its variance or covariance around the mean</p> \[\begin{align} P_s=\mathbb{E}[\hat{\theta}_s(y)-\theta][\hat{\theta}_s(y)-\theta]^T. \label{eq:cov} \end{align}\] <p>An estimator \(\hat{\theta}_1(y)\) is said to be more efficient than an estimator \(\hat{\theta}_2(y)\) if</p> \[P_1 \leq P_2.\] <p>where \(\leq\) is the matrix inequality.</p> <p><strong>[Consistent]</strong></p> <p>The estimator is said to be <em>consistent</em> if</p> \[\begin{align} \hat{\theta}(y^n) \rightarrow \theta \text{ as } n \rightarrow \infty. \label{eq:consistent} \end{align}\] <p>Since \(\hat{\theta}(y^n)\) is a random variable, we must specify in what sense this holds. Thus, if \(\eqref{eq:consistent}\) hold w.p.1, it is <em>strongly consistent</em>.</p> <p><strong>[Asumpototic distribution]</strong></p> <p>Central limit theorem can often be applied to \(\hat{\theta}(y^n)\) to infer that \(\sqrt{N}(\hat{\theta}_N -\theta)\) is asymptotically normal with zero mean as \(n\rightarrow \infty\).</p> <p><strong>[The Cramér-Rao Inequality]</strong></p> <p>Naturally, we hope that the estimators are as efficient as possible, ie. ones that make the covariance matrix \(\eqref{eq:cov}\) as small as possible. There is a theoretical lower limit called Cramér-Rao inequality.</p> <p><strong>[Theorem 1]</strong> Suppose that \(y(i)\) may take values in interval, whose limits do not depend on \(\theta\). Suppose that \(\theta\) is a real scalar and that \(f(\theta;\cdot)\) in \(\eqref{eq:f_density}\) is twice continuously differentiable with respect to \(\theta\). Let \(\hat{\theta}(y^n)\) be an estimator of \(\theta\) with expected value \(\mathbb{E}_\theta \hat{\theta}(y^n)=\gamma(\theta)\), which is assumed to be differentiable with respect to \(\theta\). Then</p> \[\mathbb{E}_\theta [\hat{\theta}(y^n)-\gamma(\theta)]^2 \leq -\frac{[d\gamma(\theta)/d\theta^2]}{\mathbb{E}_\theta \partial^2 \log f(\theta;\gamma^n)/\partial \theta^2}.\] <p><em>Proof</em> By definition \(\mathbb{E}_\theta \hat{\theta}(y^n) = \int \hat{\theta}(x^n)f(\theta;x^n)dx^n=\gamma(\theta).\)</p> <p>Differentiate w.r.t \(\theta\):</p> \[\int \hat{\theta}(x^n)\frac{\partial}{\partial \theta}f(\theta;x^n)dx^n \\ = \int \hat{\theta}(x^n) \left \{ \frac{\partial}{\partial \theta}\log f(\theta;x^n)dx^n f(\theta;x^n)dx^n \right \}\\ =\mathbb{E}_\theta \hat{\theta}(y^n) \frac{\partial}{\partial \theta}\log f(\theta;y^n)\\ =\frac{d}{d\theta}\gamma(\theta).\] <p>Since</p> \[\int f(\theta;x^n)dx^n =1,\] <p>we have</p> \[\begin{align} \int \frac{\partial}{\partial \theta}f(\theta;x^n)dx^n = 0\\ \int \frac{\partial}{\partial \theta}\log f(\theta;x^n)\cdot f(\theta;x^n) dx^n = 0 \label{eq:first_dif} \end{align}\] <p>or</p> \[\mathbb{E}_\theta \frac{\partial}{\partial \theta}\log f(\theta; y^n)=0\] <p>and</p> \[\mathbb{E}_\theta \gamma(\theta) \frac{\partial}{\partial \theta}\log f(\theta; y^n)\\ = \gamma(\theta) \mathbb{E}_\theta\frac{\partial}{\partial \theta}\log f(\theta; y^n) \\ =0\] <p>Note that \(\gamma(\theta)\) is a constant with respect to the random variable \(y^n\).<br/> Substracting this from previous expression gives</p> <p>\(\mathbb{E}_\theta [\hat{\theta}(y^n) - \gamma(\theta)] \frac{\partial}{\partial \theta}\log f(\theta; y^n) = \frac{d}{d\theta}\gamma(\theta).\) The Schwartz inequality now gives</p> \[\begin{align} \left [ \frac{d}{d\theta}\gamma(\theta) \right]^2 \leq \mathbb{E}_\theta [\hat{\theta}(y^n) - \gamma(\theta)]^2 \cdot \mathbb{E}_\theta \left [\frac{\partial}{\partial \theta}\log f(\theta; y^n)\right]^2. \\ \left(\mathbb{E}_\theta[XY])^2 \leq \mathbb{E}_\theta[X]^2 \mathbb{E}_\theta[Y]^2 \right) \label{eq:proof1} \end{align}\] <p>Also by differentiating \(\eqref{eq:first_dif}\),</p> \[\begin{align} \int \left \{ \frac{\partial^2}{\partial \theta^2}\log f(\theta;x^n) + \left [ \frac{\partial^2}{\partial \theta^2}\log f(\theta;x^n) \right]^2 \right \} f(\theta;x^n) = 0. \\ \left[ \frac{\partial^2}{\partial \theta^2}\log f(\theta;x^n) \right]^2 \Rightarrow -\frac{\partial^2}{\partial \theta^2}\log f(\theta;x^n) \label{eq:proof2} \end{align}\] <p>Combing \(\eqref{eq:proof1}\) and \(\eqref{eq:proof2}\), we get</p> \[\mathbb{E}_\theta [\hat{\theta}(y^n)-\gamma(\theta)]^2 \leq -\frac{[d\gamma(\theta)/d\theta^2]}{\mathbb{E}_\theta \partial^2 \log f(\theta;\gamma^n)/\partial \theta^2}\] <p><strong>[Corllary]</strong> Let \(\hat{\theta}(y^n)\) be a vector-valued unbiased estimator of \(\theta\). Then \(\mathbb{E} [\hat{\theta}(y^n)-\theta] [\hat{\theta}(y^n)-\theta]^T \geq M^{-1}\), where \(M = \mathbb{E}_\theta \left[ \frac{\partial}{\partial \theta}\log f(\theta; y^n) \right ] \left[ \frac{\partial}{\partial \theta}\log f(\theta; y^n) \right ]^T \\ =\mathbb{E}_\theta \frac{\partial^2}{\partial \theta^2} \log f(\theta; y^n)\) is the expected value of the second derivative matrix (the Hessian) of the function \(-\log f\), also known as the fisher information matrix.</p> <h3 id="optimal-choice-of-weights-in-quadratic-criteria">Optimal Choice of Weights in Quadratic Criteria</h3> <p>Now we want to know the optimal choice of the weighting matrix in \(l(t,\theta,\varepsilon) = \frac{1}{2}\varepsilon^T\Lambda^{-1}\varepsilon.\) To do so, we make the assumption that \(\theta^*=\theta_\circ\) where \(\{\varepsilon(t, \theta_\circ)\}\) is a sequence of indenpendet random vectors with zero means and covariance matrices \(\Lambda_\circ\).</p> <p>With asymptotic convariance matrix \(\eqref{eq:app_P}\), we find here</p> <p>\(\begin{align} P = \left [ \mathbb{E} \psi(t, \theta_\circ) \Lambda^{-1} \psi(t, \theta_\circ) \right]^{-1} \mathbb{E} \psi(t, \theta_\circ) \Lambda^{-1} \Lambda_\circ \Lambda^{-1} \psi(t, \theta_\circ) \times \left [ \mathbb{E} \psi(t, \theta_\circ) \Lambda^{-1} \psi(t, \theta_\circ) \right]^{-1}. \label{eq:P_lambda} \end{align}\) where \(\left [ \frac{d}{d\theta} \hat{y}(t\vert \theta \right )] = \psi (t, \theta)\). \(P\) can be seen as a function of \(\Lambda\) and the minimal value of \(P\) is obtained for \(\Lambda=\Lambda_\circ\). Then, we also get best estimates \(\hat{\theta}_N\) in the sense that they are closet to \(\theta_\circ\) according to \(\eqref{eq:P_lambda}\).</p>]]></content><author><name></name></author><category term="control"/><category term="linear_model"/><summary type="html"><![CDATA[Aspects of Offline Identification]]></summary></entry></feed>